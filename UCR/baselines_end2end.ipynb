{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-coverage",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from utils.utils import create_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "square-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "base_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "archive_name = 'UCRArchive_2018'\n",
    "datasets_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "seeing-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_name):\n",
    "    root_dir_dataset = base_dir + '/' + archive_name + '/' + dataset_name\n",
    "    \n",
    "    df_train = pd.read_csv(root_dir_dataset + '/' + dataset_name + '_TRAIN.tsv', sep='\\t', header=None)\n",
    "    \n",
    "    df_test = pd.read_csv(root_dir_dataset + '/' + dataset_name + '_TEST.tsv', sep='\\t', header=None)\n",
    "    \n",
    "    y_train = df_train.values[:, 0]\n",
    "    y_test = df_test.values[:, 0]\n",
    "    \n",
    "    x_train = df_train.drop(columns=[0])\n",
    "    x_test = df_test.drop(columns=[0])\n",
    "    \n",
    "    x_train.columns = range(x_train.shape[1])\n",
    "    x_test.columns = range(x_test.shape[1])\n",
    "    \n",
    "    x_train = x_train.values\n",
    "    x_test = x_test.values\n",
    "    \n",
    "    \n",
    "    labels = np.hstack((y_train, y_test)).astype(int)\n",
    "    _, labels = np.unique(labels, return_inverse=True)\n",
    "    features = np.vstack((x_train, x_test))\n",
    "    \n",
    "    \n",
    "    n_ = features.shape[0]\n",
    "    shuffle_id = np.random.permutation(np.arange(n_))\n",
    "    Dataset = features[shuffle_id]\n",
    "    label = labels[shuffle_id]\n",
    "    \n",
    "    n_train = 35#int(n_*0.1)\n",
    "    print(n_train)\n",
    "    training_set = Dataset[:n_train]\n",
    "    test_set = Dataset[n_train:]\n",
    "    training_label = label[:n_train]\n",
    "    test_label = label[n_train:]\n",
    "    \n",
    "    datasets_dict[dataset_name] = (training_set, training_label, test_set, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-affair",
   "metadata": {},
   "source": [
    "# 1. Wafer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stuffed-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "#dataset_name = 'ItalyPowerDemand'\n",
    "dataset_name = 'Wafer'\n",
    "\n",
    "read_dataset(dataset_name)\n",
    "training_set, training_label, test_set, test_label = datasets_dict[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "handled-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "for i in range(4):\n",
    "    plt.plot(training_set[training_label==1][i,1:])\n",
    "plt.subplot(1,2,2)    \n",
    "for i in range(4):\n",
    "    plt.plot(training_set[training_label==0][i,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hungarian-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = datasets_dict[dataset_name][0]\n",
    "y_train = datasets_dict[dataset_name][1]\n",
    "x_test = datasets_dict[dataset_name][2]\n",
    "y_test = datasets_dict[dataset_name][3]\n",
    "\n",
    "nb_classes = len(np.unique(np.concatenate((y_train, y_test), axis=0)))\n",
    "\n",
    "# transform the labels from integers to one hot vectors\n",
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "# save orignal y because later we will use binary\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "if len(x_train.shape) == 2:  # if univariate\n",
    "    # add a dimension to make it multivariate with one dimension \n",
    "    x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "input_shape = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "optional-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "silent-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import save_logs\n",
    "from utils.utils import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "synthetic-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epochs=200\n",
    "lr = 0.0005\n",
    "batch_size = 32\n",
    "nb_epochs = 200\n",
    "\n",
    "mini_batch_size = int(min(x_train.shape[0]/10, batch_size))\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-penguin",
   "metadata": {},
   "source": [
    "## 1.0 1D-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-dover",
   "metadata": {},
   "source": [
    "## 1.1 FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "assigned-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path =  base_dir + '/models/' + dataset_name + '_fcn/'\n",
    "create_directory(out_path)\n",
    "file_path = out_path + 'best_model.hdf5'\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss', save_best_only=True)\n",
    "callbacks = [reduce_lr,model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "adequate-direction",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "conv1 = keras.layers.Conv1D(filters=128, kernel_size=8, padding='same')(input_layer)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "\n",
    "conv2 = keras.layers.Conv1D(filters=128, kernel_size=5, padding='same')(conv1)\n",
    "conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "conv2 = keras.layers.Activation('relu')(conv2)\n",
    "\n",
    "conv3 = keras.layers.Conv1D(256, kernel_size=3,padding='same')(conv2)\n",
    "conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "conv3 = keras.layers.Activation('relu')(conv3)\n",
    "\n",
    "gap_layer = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "premier-latino",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 24, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 24, 128)           1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 24, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 24, 256)           98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 184,322\n",
      "Trainable params: 183,298\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fcn_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "fcn_model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "fcn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "specific-commercial",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9504\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 6.9795e-04 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9514\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 49ms/step - loss: 3.4735e-04 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9514\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 48ms/step - loss: 6.3840e-04 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9514\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 48ms/step - loss: 3.2320e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9534\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 49ms/step - loss: 3.2605e-04 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9524\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 49ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9483\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2913 - val_accuracy: 0.9422\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 49ms/step - loss: 7.5773e-04 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9493\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 48ms/step - loss: 7.0818e-04 - accuracy: 1.0000 - val_loss: 0.2875 - val_accuracy: 0.9493\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 1.5080e-04 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9483\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 48ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 0.9463\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 48ms/step - loss: 8.4441e-04 - accuracy: 1.0000 - val_loss: 0.3278 - val_accuracy: 0.9402\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 48ms/step - loss: 6.6767e-04 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9311\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 48ms/step - loss: 3.7089e-04 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9291\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 2.9233e-04 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9311\n",
      "Epoch 17/200\n",
      " 8/11 [====================>.........] - ETA: 0s - loss: 3.6163e-04 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-493-49c159d12e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                      callbacks=callbacks)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############ train ############\n",
    "hist = fcn_model.fit(x_train,\n",
    "                     y_train,\n",
    "                     batch_size=mini_batch_size,\n",
    "                     epochs=nb_epochs,\n",
    "                     validation_data=(x_test,y_test),\n",
    "                     callbacks=callbacks)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "chubby-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fcn = fcn_model.predict(x_test)\n",
    "y_pred_fcn = np.argmax(y_pred_fcn , axis=1)\n",
    "\n",
    "fcn_model.save(file_path)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "realistic-mathematics",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############ load ############\n",
    "#fcn_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "fcn_model.load_weights(file_path)\n",
    "\n",
    "y_pred_fcn = fcn_model.predict(x_test)\n",
    "y_pred_fcn = np.argmax(y_pred_fcn , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "automatic-cooperation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9606525911708254\n",
      "recall: 0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:',accuracy_score(y_pred_fcn,y_true))\n",
    "print('recall:',recall_score(1-y_pred_fcn,1-y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-crowd",
   "metadata": {},
   "source": [
    "## 1.2 Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "advance-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path =  base_dir + '/models/' + dataset_name + '_Incep/'\n",
    "create_directory(out_path)\n",
    "file_path = out_path + 'best_model.hdf5'\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss', save_best_only=True)\n",
    "callbacks = [reduce_lr,model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "refined-honor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _inception_module(input_tensor, stride=1, activation='linear'):\n",
    "    \n",
    "    use_bottleneck=True\n",
    "    bottleneck_size = 16\n",
    "    kernel_size = 5\n",
    "    nb_filters = 32\n",
    "    \n",
    "    if use_bottleneck and int(input_tensor.shape[-1]) > bottleneck_size:\n",
    "        input_inception = keras.layers.Conv1D(filters=bottleneck_size, kernel_size=1,\n",
    "                                              padding='same', activation=activation, use_bias=False)(input_tensor)\n",
    "    else:\n",
    "        input_inception = input_tensor\n",
    "\n",
    "    # kernel_size_s = [3, 5, 8, 11, 17]\n",
    "    kernel_size_s = [kernel_size // (2 ** i) for i in range(3)]\n",
    "\n",
    "    conv_list = []\n",
    "\n",
    "    for i in range(len(kernel_size_s)):\n",
    "        conv_list.append(keras.layers.Conv1D(filters=nb_filters, kernel_size=kernel_size_s[i],\n",
    "                                             strides=stride, padding='same', activation=activation, use_bias=False)(\n",
    "            input_inception))\n",
    "\n",
    "    max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
    "\n",
    "    conv_6 = keras.layers.Conv1D(filters=nb_filters, kernel_size=1,\n",
    "                                 padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
    "\n",
    "    conv_list.append(conv_6)\n",
    "\n",
    "    x = keras.layers.Concatenate(axis=2)(conv_list)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation(activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "def _shortcut_layer(input_tensor, out_tensor):\n",
    "    \n",
    "    shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
    "                                     padding='same', use_bias=False)(input_tensor)\n",
    "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "    x = keras.layers.Add()([shortcut_y, out_tensor])\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "visible-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_residual=True\n",
    "depth = 3\n",
    "\n",
    "input_layer = keras.layers.Input(input_shape)\n",
    "x = input_layer\n",
    "input_res = input_layer\n",
    "for d in range(depth):\n",
    "\n",
    "    x = _inception_module(x)\n",
    "\n",
    "    if use_residual and d % 3 == 2:\n",
    "        x = _shortcut_layer(input_res, x)\n",
    "        input_res = x\n",
    "\n",
    "gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
    "output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "minor-semester",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 152, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 152, 1)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 152, 32)      160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 152, 32)      64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 152, 32)      32          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 152, 32)      32          max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 152, 128)     0           conv1d[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 152, 128)     512         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 152, 128)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 152, 16)      2048        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 152, 128)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 152, 32)      2560        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 152, 32)      1024        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 152, 32)      512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 152, 32)      4096        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 152, 128)     0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 152, 128)     512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 152, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 152, 16)      2048        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 152, 128)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 152, 32)      2560        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 152, 32)      1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 152, 32)      512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 152, 32)      4096        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 152, 128)     0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 152, 128)     128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 152, 128)     512         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 152, 128)     512         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 152, 128)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 152, 128)     0           batch_normalization_3[0][0]      \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 152, 128)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            258         global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 23,202\n",
      "Trainable params: 22,178\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Incep_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "Incep_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr),metrics=['accuracy'])\n",
    "Incep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "finnish-person",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 3s 56ms/step - loss: 0.4496 - accuracy: 0.8571\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3436 - accuracy: 0.8857\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3457 - accuracy: 0.8857\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3380 - accuracy: 0.8857\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3327 - accuracy: 0.8857\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3112 - accuracy: 0.8857\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3120 - accuracy: 0.8857\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3289 - accuracy: 0.8857\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.3132 - accuracy: 0.8857\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3095 - accuracy: 0.8857\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3194 - accuracy: 0.8857\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2925 - accuracy: 0.8857\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3074 - accuracy: 0.8857\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.8857\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.3088 - accuracy: 0.8857\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3015 - accuracy: 0.8857\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.3112 - accuracy: 0.8857\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2759 - accuracy: 0.8857\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2792 - accuracy: 0.8857\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2800 - accuracy: 0.8857\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2789 - accuracy: 0.9143\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2769 - accuracy: 0.8857\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2596 - accuracy: 0.8857\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2684 - accuracy: 0.9143\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2383 - accuracy: 0.8857\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3096 - accuracy: 0.8857\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2435 - accuracy: 0.8857\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2542 - accuracy: 0.9143\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.2552 - accuracy: 0.8857\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2632 - accuracy: 0.8857\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2434 - accuracy: 0.9143\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2609 - accuracy: 0.8857\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2503 - accuracy: 0.9143\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2256 - accuracy: 0.9143\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2039 - accuracy: 0.9143\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2093 - accuracy: 0.8857\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2333 - accuracy: 0.9143\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2046 - accuracy: 0.9143\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2244 - accuracy: 0.9143\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1932 - accuracy: 0.9143\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2092 - accuracy: 0.9429\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1921 - accuracy: 0.9143\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2208 - accuracy: 0.9143\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1940 - accuracy: 0.9429\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1670 - accuracy: 0.9429\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2324 - accuracy: 0.9143\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1826 - accuracy: 0.9429\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1620 - accuracy: 0.9143\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1626 - accuracy: 0.9429\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2053 - accuracy: 0.9143\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1290 - accuracy: 0.9714\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2427 - accuracy: 0.9143\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1395 - accuracy: 0.9714\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1521 - accuracy: 0.9429\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1848 - accuracy: 0.9143\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1773 - accuracy: 0.9429\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.1516 - accuracy: 0.9143\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.2608 - accuracy: 0.9429\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.2022 - accuracy: 0.9143\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1911 - accuracy: 0.8857\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1789 - accuracy: 0.9143\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1522 - accuracy: 0.9429\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1104 - accuracy: 0.9714\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1151 - accuracy: 0.9714\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1760 - accuracy: 0.9143\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1326 - accuracy: 0.9143\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1576 - accuracy: 0.9429\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0986 - accuracy: 0.9714\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0944 - accuracy: 0.9714\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0760 - accuracy: 0.9714\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1801 - accuracy: 0.9429\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1199 - accuracy: 0.9429\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1043 - accuracy: 0.9714\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0929 - accuracy: 0.9714\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1057 - accuracy: 0.9714\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1923 - accuracy: 0.9429\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1506 - accuracy: 0.9714\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1461 - accuracy: 0.9429\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0780 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1386 - accuracy: 0.9714\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1799 - accuracy: 0.9429\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1408 - accuracy: 0.9429\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1527 - accuracy: 0.9429\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1100 - accuracy: 0.9429\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1570 - accuracy: 0.9714\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0999 - accuracy: 0.9714\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0917 - accuracy: 0.9714\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1335 - accuracy: 0.9429\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0863 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.1311 - accuracy: 0.9714\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1382 - accuracy: 0.9143\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0749 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1278 - accuracy: 0.9143\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1219 - accuracy: 0.9714\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0895 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0908 - accuracy: 0.9714\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1290 - accuracy: 0.9429\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1111 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1182 - accuracy: 0.9714\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0733 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0651 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0775 - accuracy: 0.9714\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.1517 - accuracy: 0.9714\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0639 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0630 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0749 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      " 9/12 [=====================>........] - ETA: 0s - loss: 0.0713 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6e66c880ad5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                        \u001b[0;31m#validation_data=(x_test,y_test),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                        callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############ train ############\n",
    "hist = Incep_model.fit(x_train,\n",
    "                       y_train,\n",
    "                       batch_size=mini_batch_size,\n",
    "                       epochs=nb_epochs,\n",
    "                       #validation_data=(x_test,y_test),\n",
    "                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "excessive-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Incep_model.predict(x_test)\n",
    "y_pred_fcn = np.argmax(y_pred , axis=1)\n",
    "\n",
    "Incep_model.save(file_path)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "vital-partnership",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############ load ############\n",
    "#Incep_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "Incep_model.load_weights(file_path)\n",
    "\n",
    "y_pred_Incep = Incep_model.predict(x_test)\n",
    "y_pred_Incep = np.argmax(y_pred_Incep , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "desperate-worth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9531491092719877\n",
      "recall: 0.8617747440273038\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:',accuracy_score(y_pred_fcn,y_true))\n",
    "print('recall:',recall_score(1-y_pred_fcn,1-y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-jaguar",
   "metadata": {},
   "source": [
    "## 1.3 Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "departmental-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path =  base_dir + '/models/' + dataset_name + '_resnet/'\n",
    "create_directory(out_path)\n",
    "file_path = out_path + 'best_model.hdf5'\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss', save_best_only=True)\n",
    "callbacks = [reduce_lr,model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "returning-ireland",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_feature_maps = 40\n",
    "input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "# BLOCK 1\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "# expand channels for the sum\n",
    "shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
    "shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "\n",
    "# BLOCK 2\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "# expand channels for the sum\n",
    "shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "\n",
    "# BLOCK 3\n",
    "\n",
    "conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
    "conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "# no need to expand channels because they are equal\n",
    "shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "\n",
    "# FINAL\n",
    "\n",
    "gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "recent-density",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 24, 40)       360         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 24, 40)       160         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 24, 40)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 24, 40)       8040        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 24, 40)       160         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 24, 40)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 24, 40)       80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 24, 40)       4840        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 24, 40)       160         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 24, 40)       160         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 24, 40)       0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 40)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 24, 80)       25680       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 80)       320         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 24, 80)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 24, 80)       32080       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 24, 80)       320         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 80)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 24, 80)       3280        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 24, 80)       19280       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 24, 80)       320         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 24, 80)       320         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24, 80)       0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 24, 80)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 24, 80)       51280       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 24, 80)       320         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 24, 80)       0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 24, 80)       32080       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 24, 80)       320         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 24, 80)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 24, 80)       19280       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 24, 80)       320         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 24, 80)       320         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 24, 80)       0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 24, 80)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 80)           0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            162         global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 199,642\n",
      "Trainable params: 198,042\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Resnet_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "Resnet_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "Resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "pediatric-bandwidth",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9412\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 5.7567e-04 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9412\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9433\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 8.4236e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9483\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 8.0660e-04 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9473\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2309 - val_accuracy: 0.9433\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 9.3836e-04 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9422\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7.8733e-04 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9433\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 5.4996e-04 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9422\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 7.8301e-04 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9402\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 7.1171e-04 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9453\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 9.1312e-04 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.9453\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 9.4083e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9473\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9453\n",
      "Epoch 15/200\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 4.1075e-04 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-503-52892688581a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############ train ############\n",
    "hist = Resnet_model.fit(x_train,\n",
    "                        y_train,\n",
    "                        batch_size=mini_batch_size,\n",
    "                        epochs=nb_epochs,\n",
    "                        validation_data=(x_test,y_test),\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "instant-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Resnet_model.predict(x_test)\n",
    "y_pred_fcn = np.argmax(y_pred , axis=1)\n",
    "\n",
    "Resnet_model.save(file_path)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "devoted-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ load ############\n",
    "#Resnet_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "Resnet_model.load_weights(file_path)\n",
    "\n",
    "y_pred_Incep = Resnet_model.predict(x_test)\n",
    "y_pred_Incep = np.argmax(y_pred_Incep , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "homeless-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9432624113475178\n",
      "recall: 0.9382470119521913\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:',accuracy_score(y_pred_fcn,y_true))\n",
    "print('recall:',recall_score(1-y_pred_fcn,1-y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-worker",
   "metadata": {},
   "source": [
    "# 1.4 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "illegal-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path =  base_dir + '/models/' + dataset_name + '_mlp/'\n",
    "create_directory(out_path)\n",
    "file_path = out_path + 'best_model.hdf5'\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss', save_best_only=True)\n",
    "callbacks = [reduce_lr,model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "persistent-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "# flatten/reshape because when multivariate all should be on the same axis \n",
    "input_layer_flattened = keras.layers.Flatten()(input_layer)\n",
    "\n",
    "layer_1 = keras.layers.Dropout(0.1)(input_layer_flattened)\n",
    "layer_1 = keras.layers.Dense(300, activation='relu')(layer_1)\n",
    "\n",
    "layer_2 = keras.layers.Dropout(0.2)(layer_1)\n",
    "layer_2 = keras.layers.Dense(300, activation='relu')(layer_2)\n",
    "\n",
    "layer_3 = keras.layers.Dropout(0.2)(layer_2)\n",
    "layer_3 = keras.layers.Dense(300, activation='relu')(layer_3)\n",
    "\n",
    "output_layer = keras.layers.Dropout(0.3)(layer_3)\n",
    "output_layer = keras.layers.Dense(nb_classes, activation='softmax')(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "pregnant-validation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 24, 1)]           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               7500      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 188,702\n",
      "Trainable params: 188,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "mlp_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "jewish-maintenance",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.4600\n",
      "Epoch 2/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7701 - accuracy: 0.4086\n",
      "Epoch 3/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.5135\n",
      "Epoch 4/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.5114\n",
      "Epoch 5/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7766 - accuracy: 0.4013\n",
      "Epoch 6/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7867 - accuracy: 0.4011\n",
      "Epoch 7/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7815 - accuracy: 0.4401\n",
      "Epoch 8/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.5519\n",
      "Epoch 9/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7851 - accuracy: 0.4379\n",
      "Epoch 10/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.6204\n",
      "Epoch 11/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7826 - accuracy: 0.4049\n",
      "Epoch 12/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6328\n",
      "Epoch 13/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7112 - accuracy: 0.4524\n",
      "Epoch 14/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7974 - accuracy: 0.4489\n",
      "Epoch 15/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7078 - accuracy: 0.5241\n",
      "Epoch 16/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.4711\n",
      "Epoch 17/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.4850\n",
      "Epoch 18/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.5440\n",
      "Epoch 19/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.4302\n",
      "Epoch 20/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.5556\n",
      "Epoch 21/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7475 - accuracy: 0.4540\n",
      "Epoch 22/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.4206\n",
      "Epoch 23/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7690 - accuracy: 0.5088\n",
      "Epoch 24/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7988 - accuracy: 0.4302\n",
      "Epoch 25/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7689 - accuracy: 0.4220\n",
      "Epoch 26/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6370\n",
      "Epoch 27/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7417 - accuracy: 0.5500\n",
      "Epoch 28/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.5442\n",
      "Epoch 29/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.5669\n",
      "Epoch 30/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7171 - accuracy: 0.5679\n",
      "Epoch 31/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.5426\n",
      "Epoch 32/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7457 - accuracy: 0.4712\n",
      "Epoch 33/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.5471\n",
      "Epoch 34/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7588 - accuracy: 0.4551\n",
      "Epoch 35/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7499 - accuracy: 0.3754\n",
      "Epoch 36/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.4554\n",
      "Epoch 37/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.5686\n",
      "Epoch 38/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7354 - accuracy: 0.4403\n",
      "Epoch 39/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.5434\n",
      "Epoch 40/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.5436\n",
      "Epoch 41/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.4534\n",
      "Epoch 42/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.5006\n",
      "Epoch 43/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7238 - accuracy: 0.5209\n",
      "Epoch 44/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7156 - accuracy: 0.4830\n",
      "Epoch 45/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7199 - accuracy: 0.5031\n",
      "Epoch 46/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5486\n",
      "Epoch 47/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7484 - accuracy: 0.4495\n",
      "Epoch 48/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5431\n",
      "Epoch 49/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.4776\n",
      "Epoch 50/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.5579\n",
      "Epoch 51/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.5290\n",
      "Epoch 52/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7311 - accuracy: 0.4961\n",
      "Epoch 53/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.5636\n",
      "Epoch 54/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7317 - accuracy: 0.4486\n",
      "Epoch 55/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.4782\n",
      "Epoch 56/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.4265\n",
      "Epoch 57/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.6442\n",
      "Epoch 58/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.5919\n",
      "Epoch 59/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.5650\n",
      "Epoch 60/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.4792\n",
      "Epoch 61/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7427 - accuracy: 0.4018\n",
      "Epoch 62/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.5090\n",
      "Epoch 63/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7159 - accuracy: 0.4749\n",
      "Epoch 64/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.5924\n",
      "Epoch 65/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7322 - accuracy: 0.4669\n",
      "Epoch 66/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.5564\n",
      "Epoch 67/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7351 - accuracy: 0.5517\n",
      "Epoch 68/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5504\n",
      "Epoch 69/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7182 - accuracy: 0.4185\n",
      "Epoch 70/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7677 - accuracy: 0.4183\n",
      "Epoch 71/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7159 - accuracy: 0.5613\n",
      "Epoch 72/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7254 - accuracy: 0.5322\n",
      "Epoch 73/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7484 - accuracy: 0.4547\n",
      "Epoch 74/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7316 - accuracy: 0.4651\n",
      "Epoch 75/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.5818\n",
      "Epoch 76/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5829\n",
      "Epoch 77/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.5674\n",
      "Epoch 78/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7298 - accuracy: 0.5254\n",
      "Epoch 79/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5449\n",
      "Epoch 80/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.4778\n",
      "Epoch 81/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7379 - accuracy: 0.4462\n",
      "Epoch 82/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.5282\n",
      "Epoch 83/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.5913\n",
      "Epoch 84/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7137 - accuracy: 0.6043\n",
      "Epoch 85/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.4767\n",
      "Epoch 86/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.5318\n",
      "Epoch 87/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7073 - accuracy: 0.5397\n",
      "Epoch 88/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6406 - accuracy: 0.6122\n",
      "Epoch 89/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7080 - accuracy: 0.5230\n",
      "Epoch 90/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6254 - accuracy: 0.6482\n",
      "Epoch 91/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.5410\n",
      "Epoch 92/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.5438\n",
      "Epoch 93/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5094\n",
      "Epoch 94/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.5911\n",
      "Epoch 95/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.5975\n",
      "Epoch 96/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.5533\n",
      "Epoch 97/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.5338\n",
      "Epoch 98/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.4718\n",
      "Epoch 99/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.6217\n",
      "Epoch 100/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.5100\n",
      "Epoch 101/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.5815\n",
      "Epoch 102/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.6293\n",
      "Epoch 103/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.5413\n",
      "Epoch 104/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.5627\n",
      "Epoch 105/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.4851\n",
      "Epoch 106/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6415\n",
      "Epoch 107/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.5276\n",
      "Epoch 108/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6194\n",
      "Epoch 109/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6721 - accuracy: 0.6088\n",
      "Epoch 110/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.6426\n",
      "Epoch 111/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5889\n",
      "Epoch 112/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6681\n",
      "Epoch 113/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6052\n",
      "Epoch 114/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.5618\n",
      "Epoch 115/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.5761\n",
      "Epoch 116/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5159\n",
      "Epoch 117/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.5770\n",
      "Epoch 118/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.4758\n",
      "Epoch 119/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5657\n",
      "Epoch 120/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6980 - accuracy: 0.5508\n",
      "Epoch 121/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6357 - accuracy: 0.6088\n",
      "Epoch 122/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.4397\n",
      "Epoch 123/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.5897\n",
      "Epoch 124/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.6723\n",
      "Epoch 125/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5053\n",
      "Epoch 126/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.5391\n",
      "Epoch 127/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.6093\n",
      "Epoch 128/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6769 - accuracy: 0.4830\n",
      "Epoch 129/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.5958\n",
      "Epoch 130/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.5836\n",
      "Epoch 131/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7015 - accuracy: 0.4633\n",
      "Epoch 132/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6805\n",
      "Epoch 133/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5415\n",
      "Epoch 134/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5250\n",
      "Epoch 135/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.5488\n",
      "Epoch 136/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5895\n",
      "Epoch 137/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5259\n",
      "Epoch 138/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.4527\n",
      "Epoch 139/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.5494\n",
      "Epoch 140/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6944 - accuracy: 0.5880\n",
      "Epoch 141/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4596\n",
      "Epoch 142/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.6107\n",
      "Epoch 143/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.5258\n",
      "Epoch 144/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.5078\n",
      "Epoch 145/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.5428\n",
      "Epoch 146/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.5436\n",
      "Epoch 147/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5193\n",
      "Epoch 148/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.5788\n",
      "Epoch 149/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.5053\n",
      "Epoch 150/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.5775\n",
      "Epoch 151/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.6209\n",
      "Epoch 152/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.5496\n",
      "Epoch 153/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.5959\n",
      "Epoch 154/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.5593\n",
      "Epoch 155/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.5946\n",
      "Epoch 156/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.5120\n",
      "Epoch 157/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.5991\n",
      "Epoch 158/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.5836\n",
      "Epoch 159/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.5217\n",
      "Epoch 160/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.6294\n",
      "Epoch 161/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.5806\n",
      "Epoch 162/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5664\n",
      "Epoch 163/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.5940\n",
      "Epoch 164/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.5821\n",
      "Epoch 165/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7019 - accuracy: 0.5600\n",
      "Epoch 166/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5814\n",
      "Epoch 167/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.6152\n",
      "Epoch 168/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.6233\n",
      "Epoch 169/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.5848\n",
      "Epoch 170/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.5462\n",
      "Epoch 171/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.6632\n",
      "Epoch 172/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.5015\n",
      "Epoch 173/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.6193\n",
      "Epoch 174/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5297\n",
      "Epoch 175/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7224 - accuracy: 0.4613\n",
      "Epoch 176/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.5075\n",
      "Epoch 177/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.6162\n",
      "Epoch 178/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.5819\n",
      "Epoch 179/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.5415\n",
      "Epoch 180/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.5925\n",
      "Epoch 181/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6386\n",
      "Epoch 182/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.5542\n",
      "Epoch 183/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6058\n",
      "Epoch 184/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.6046\n",
      "Epoch 185/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7202 - accuracy: 0.5241\n",
      "Epoch 186/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.5919\n",
      "Epoch 187/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6236 - accuracy: 0.5562\n",
      "Epoch 188/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.6061\n",
      "Epoch 189/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7185 - accuracy: 0.4476\n",
      "Epoch 190/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6260\n",
      "Epoch 191/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.5275\n",
      "Epoch 192/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6053\n",
      "Epoch 193/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.5202\n",
      "Epoch 194/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.6579\n",
      "Epoch 195/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.5532\n",
      "Epoch 196/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.7465\n",
      "Epoch 197/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6150\n",
      "Epoch 198/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.6844\n",
      "Epoch 199/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.5794\n",
      "Epoch 200/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7421\n",
      "Epoch 201/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6435\n",
      "Epoch 202/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6432\n",
      "Epoch 203/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.5281\n",
      "Epoch 204/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.6098\n",
      "Epoch 205/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.6007\n",
      "Epoch 206/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5711\n",
      "Epoch 207/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6534\n",
      "Epoch 208/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6762\n",
      "Epoch 209/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6850\n",
      "Epoch 210/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.6094\n",
      "Epoch 211/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6771\n",
      "Epoch 212/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.6095\n",
      "Epoch 213/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.5573\n",
      "Epoch 214/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6792\n",
      "Epoch 215/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6684\n",
      "Epoch 216/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.6359\n",
      "Epoch 217/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6935\n",
      "Epoch 218/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6845\n",
      "Epoch 219/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.4636\n",
      "Epoch 220/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.4694\n",
      "Epoch 221/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6538\n",
      "Epoch 222/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6237\n",
      "Epoch 223/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6575 - accuracy: 0.5757\n",
      "Epoch 224/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.6059\n",
      "Epoch 225/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.5470\n",
      "Epoch 226/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6471\n",
      "Epoch 227/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6208 - accuracy: 0.7817\n",
      "Epoch 228/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6778\n",
      "Epoch 229/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.5584\n",
      "Epoch 230/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.4896\n",
      "Epoch 231/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6830\n",
      "Epoch 232/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.6891\n",
      "Epoch 233/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.5930\n",
      "Epoch 234/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.6129\n",
      "Epoch 235/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.6155\n",
      "Epoch 236/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7498\n",
      "Epoch 237/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6202 - accuracy: 0.6969\n",
      "Epoch 238/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.6372\n",
      "Epoch 239/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7213\n",
      "Epoch 240/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6060\n",
      "Epoch 241/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.5867\n",
      "Epoch 242/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6997 - accuracy: 0.5957\n",
      "Epoch 243/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7389\n",
      "Epoch 244/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6373\n",
      "Epoch 245/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5252\n",
      "Epoch 246/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.7391\n",
      "Epoch 247/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6466 - accuracy: 0.7635\n",
      "Epoch 248/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.6744\n",
      "Epoch 249/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.5103\n",
      "Epoch 250/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6859\n",
      "Epoch 251/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.5402\n",
      "Epoch 252/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7702\n",
      "Epoch 253/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5827\n",
      "Epoch 254/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.5951\n",
      "Epoch 255/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.6309\n",
      "Epoch 256/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.7148\n",
      "Epoch 257/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.6110\n",
      "Epoch 258/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6751\n",
      "Epoch 259/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5165\n",
      "Epoch 260/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6268\n",
      "Epoch 261/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6932\n",
      "Epoch 262/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5960\n",
      "Epoch 263/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.7080\n",
      "Epoch 264/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.5751\n",
      "Epoch 265/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6143\n",
      "Epoch 266/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5117\n",
      "Epoch 267/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6336 - accuracy: 0.6803\n",
      "Epoch 268/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7076\n",
      "Epoch 269/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6979\n",
      "Epoch 270/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6921\n",
      "Epoch 271/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.5901\n",
      "Epoch 272/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.7151\n",
      "Epoch 273/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5616\n",
      "Epoch 274/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7413\n",
      "Epoch 275/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.6854\n",
      "Epoch 276/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.6201\n",
      "Epoch 277/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.5827\n",
      "Epoch 278/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.6305\n",
      "Epoch 279/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.7921\n",
      "Epoch 280/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.6920\n",
      "Epoch 281/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.5818\n",
      "Epoch 282/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7449\n",
      "Epoch 283/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7004\n",
      "Epoch 284/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6459 - accuracy: 0.6148\n",
      "Epoch 285/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5753\n",
      "Epoch 286/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7644\n",
      "Epoch 287/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6025\n",
      "Epoch 288/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.7455\n",
      "Epoch 289/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.6430\n",
      "Epoch 290/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.6557\n",
      "Epoch 291/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.5961\n",
      "Epoch 292/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6275\n",
      "Epoch 293/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.7057\n",
      "Epoch 294/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.6786\n",
      "Epoch 295/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.7726\n",
      "Epoch 296/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.5273\n",
      "Epoch 297/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.5740\n",
      "Epoch 298/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.6311\n",
      "Epoch 299/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7838\n",
      "Epoch 300/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.7291\n",
      "Epoch 301/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7805\n",
      "Epoch 302/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7163\n",
      "Epoch 303/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7833\n",
      "Epoch 304/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.7278\n",
      "Epoch 305/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.6719\n",
      "Epoch 306/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7385\n",
      "Epoch 307/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.6945\n",
      "Epoch 308/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.6921\n",
      "Epoch 309/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7039\n",
      "Epoch 310/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.6846\n",
      "Epoch 311/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6170 - accuracy: 0.7617\n",
      "Epoch 312/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6819\n",
      "Epoch 313/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.5610\n",
      "Epoch 314/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6355 - accuracy: 0.6666\n",
      "Epoch 315/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.6870\n",
      "Epoch 316/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.7481\n",
      "Epoch 317/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.7119\n",
      "Epoch 318/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.5663\n",
      "Epoch 319/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6041\n",
      "Epoch 320/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.6516\n",
      "Epoch 321/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6995\n",
      "Epoch 322/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.5959\n",
      "Epoch 323/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6699\n",
      "Epoch 324/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6856\n",
      "Epoch 325/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.6101\n",
      "Epoch 326/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.7782\n",
      "Epoch 327/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.7965\n",
      "Epoch 328/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6138\n",
      "Epoch 329/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.5325\n",
      "Epoch 330/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6375\n",
      "Epoch 331/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7308\n",
      "Epoch 332/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.6499\n",
      "Epoch 333/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7178\n",
      "Epoch 334/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6135\n",
      "Epoch 335/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6168\n",
      "Epoch 336/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.6578\n",
      "Epoch 337/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.5587\n",
      "Epoch 338/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.7369\n",
      "Epoch 339/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7284\n",
      "Epoch 340/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.6730\n",
      "Epoch 341/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.7072\n",
      "Epoch 342/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6769\n",
      "Epoch 343/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.8261\n",
      "Epoch 344/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6354 - accuracy: 0.6491\n",
      "Epoch 345/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.7034\n",
      "Epoch 346/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.7465\n",
      "Epoch 347/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.5898\n",
      "Epoch 348/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6430\n",
      "Epoch 349/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.8371\n",
      "Epoch 350/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.8364\n",
      "Epoch 351/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7230\n",
      "Epoch 352/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.6543\n",
      "Epoch 353/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6875\n",
      "Epoch 354/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7828\n",
      "Epoch 355/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6147 - accuracy: 0.7296\n",
      "Epoch 356/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7744\n",
      "Epoch 357/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.6328\n",
      "Epoch 358/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6828\n",
      "Epoch 359/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7135\n",
      "Epoch 360/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6553\n",
      "Epoch 361/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.5550\n",
      "Epoch 362/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.7125\n",
      "Epoch 363/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.6840\n",
      "Epoch 364/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6471\n",
      "Epoch 365/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7302\n",
      "Epoch 366/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.7095\n",
      "Epoch 367/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.5820\n",
      "Epoch 368/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.8083\n",
      "Epoch 369/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7360\n",
      "Epoch 370/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.6364\n",
      "Epoch 371/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7432\n",
      "Epoch 372/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6662\n",
      "Epoch 373/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.7379\n",
      "Epoch 374/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7452\n",
      "Epoch 375/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.5380\n",
      "Epoch 376/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7000\n",
      "Epoch 377/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.7143\n",
      "Epoch 378/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6479 - accuracy: 0.6454\n",
      "Epoch 379/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7946\n",
      "Epoch 380/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7915\n",
      "Epoch 381/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.8135\n",
      "Epoch 382/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6795\n",
      "Epoch 383/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.8241\n",
      "Epoch 384/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.6727\n",
      "Epoch 385/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.5887\n",
      "Epoch 386/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6992\n",
      "Epoch 387/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.7193\n",
      "Epoch 388/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6536\n",
      "Epoch 389/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.7347\n",
      "Epoch 390/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.6524\n",
      "Epoch 391/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.7624\n",
      "Epoch 392/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6154\n",
      "Epoch 393/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.8175\n",
      "Epoch 394/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7356\n",
      "Epoch 395/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6590\n",
      "Epoch 396/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7648\n",
      "Epoch 397/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7092\n",
      "Epoch 398/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.7423\n",
      "Epoch 399/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.6522\n",
      "Epoch 400/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.7746\n",
      "Epoch 401/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7972\n",
      "Epoch 402/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.8701\n",
      "Epoch 403/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6373\n",
      "Epoch 404/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.5438\n",
      "Epoch 405/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7763\n",
      "Epoch 406/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6132\n",
      "Epoch 407/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6411\n",
      "Epoch 408/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7163\n",
      "Epoch 409/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6376\n",
      "Epoch 410/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.7101\n",
      "Epoch 411/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.7704\n",
      "Epoch 412/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7894\n",
      "Epoch 413/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.8103\n",
      "Epoch 414/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7409\n",
      "Epoch 415/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5940 - accuracy: 0.6905\n",
      "Epoch 416/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7893\n",
      "Epoch 417/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6689\n",
      "Epoch 418/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.7277\n",
      "Epoch 419/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6874\n",
      "Epoch 420/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7123\n",
      "Epoch 421/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7395\n",
      "Epoch 422/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6623\n",
      "Epoch 423/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.7628\n",
      "Epoch 424/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.7803\n",
      "Epoch 425/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7370\n",
      "Epoch 426/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.6824\n",
      "Epoch 427/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7720\n",
      "Epoch 428/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7205\n",
      "Epoch 429/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7077\n",
      "Epoch 430/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.7611\n",
      "Epoch 431/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.8498\n",
      "Epoch 432/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.6154\n",
      "Epoch 433/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8027\n",
      "Epoch 434/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.5987\n",
      "Epoch 435/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7722\n",
      "Epoch 436/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6655\n",
      "Epoch 437/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.7351\n",
      "Epoch 438/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.6757\n",
      "Epoch 439/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.8345\n",
      "Epoch 440/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.8167\n",
      "Epoch 441/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.7196\n",
      "Epoch 442/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.6929\n",
      "Epoch 443/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.8281\n",
      "Epoch 444/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.8120\n",
      "Epoch 445/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7475\n",
      "Epoch 446/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8300\n",
      "Epoch 447/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5941 - accuracy: 0.7630\n",
      "Epoch 448/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7494\n",
      "Epoch 449/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.8615\n",
      "Epoch 450/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.8430\n",
      "Epoch 451/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.8083\n",
      "Epoch 452/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.7395\n",
      "Epoch 453/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5995 - accuracy: 0.7111\n",
      "Epoch 454/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6057 - accuracy: 0.7092\n",
      "Epoch 455/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.8301\n",
      "Epoch 456/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7165\n",
      "Epoch 457/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.8325\n",
      "Epoch 458/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.8294\n",
      "Epoch 459/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.7460\n",
      "Epoch 460/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.8196\n",
      "Epoch 461/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7794\n",
      "Epoch 462/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.8159\n",
      "Epoch 463/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6394\n",
      "Epoch 464/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7896\n",
      "Epoch 465/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7975\n",
      "Epoch 466/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.8371\n",
      "Epoch 467/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.8425\n",
      "Epoch 468/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.9097\n",
      "Epoch 469/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.6640\n",
      "Epoch 470/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.8257\n",
      "Epoch 471/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7598\n",
      "Epoch 472/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.9222\n",
      "Epoch 473/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5955 - accuracy: 0.7481\n",
      "Epoch 474/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.7082\n",
      "Epoch 475/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6106 - accuracy: 0.7962\n",
      "Epoch 476/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.7742\n",
      "Epoch 477/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.8274\n",
      "Epoch 478/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7515\n",
      "Epoch 479/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7677\n",
      "Epoch 480/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.8228\n",
      "Epoch 481/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5539 - accuracy: 0.9043\n",
      "Epoch 482/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6160\n",
      "Epoch 483/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.7533\n",
      "Epoch 484/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7298\n",
      "Epoch 485/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7962\n",
      "Epoch 486/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7375\n",
      "Epoch 487/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.9165\n",
      "Epoch 488/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6873\n",
      "Epoch 489/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.8784\n",
      "Epoch 490/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7607\n",
      "Epoch 491/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.8123\n",
      "Epoch 492/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7277\n",
      "Epoch 493/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.8248\n",
      "Epoch 494/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.8067\n",
      "Epoch 495/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.9020\n",
      "Epoch 496/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7512\n",
      "Epoch 497/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.9055\n",
      "Epoch 498/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7297\n",
      "Epoch 499/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7694\n",
      "Epoch 500/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8337\n",
      "Epoch 501/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6931\n",
      "Epoch 502/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7928\n",
      "Epoch 503/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.8300\n",
      "Epoch 504/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.9056\n",
      "Epoch 505/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6829\n",
      "Epoch 506/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7958\n",
      "Epoch 507/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6989\n",
      "Epoch 508/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.9205\n",
      "Epoch 509/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.6595\n",
      "Epoch 510/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.7444\n",
      "Epoch 511/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6980\n",
      "Epoch 512/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.8817\n",
      "Epoch 513/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.8055\n",
      "Epoch 514/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.8098\n",
      "Epoch 515/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.8942\n",
      "Epoch 516/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7796\n",
      "Epoch 517/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7706\n",
      "Epoch 518/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.8456\n",
      "Epoch 519/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.8233\n",
      "Epoch 520/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.8877\n",
      "Epoch 521/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.7324\n",
      "Epoch 522/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.8262\n",
      "Epoch 523/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.8222\n",
      "Epoch 524/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.8393\n",
      "Epoch 525/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7474\n",
      "Epoch 526/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7345\n",
      "Epoch 527/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6998\n",
      "Epoch 528/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7065\n",
      "Epoch 529/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7276\n",
      "Epoch 530/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.8119\n",
      "Epoch 531/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.8727\n",
      "Epoch 532/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7899\n",
      "Epoch 533/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7596\n",
      "Epoch 534/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7520\n",
      "Epoch 535/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.7945\n",
      "Epoch 536/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.8513\n",
      "Epoch 537/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7645\n",
      "Epoch 538/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6763\n",
      "Epoch 539/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6776\n",
      "Epoch 540/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7394\n",
      "Epoch 541/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.7614\n",
      "Epoch 542/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6102 - accuracy: 0.7332\n",
      "Epoch 543/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7894\n",
      "Epoch 544/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6796\n",
      "Epoch 545/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7727\n",
      "Epoch 546/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.8285\n",
      "Epoch 547/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7714\n",
      "Epoch 548/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7901\n",
      "Epoch 549/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.8449\n",
      "Epoch 550/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6883\n",
      "Epoch 551/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7116\n",
      "Epoch 552/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.9377\n",
      "Epoch 553/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7827\n",
      "Epoch 554/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7982\n",
      "Epoch 555/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5913 - accuracy: 0.7605\n",
      "Epoch 556/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5784 - accuracy: 0.8069\n",
      "Epoch 557/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7350\n",
      "Epoch 558/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.7084\n",
      "Epoch 559/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7857\n",
      "Epoch 560/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.8692\n",
      "Epoch 561/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.7986\n",
      "Epoch 562/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.8655\n",
      "Epoch 563/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7674\n",
      "Epoch 564/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.8403\n",
      "Epoch 565/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.7034\n",
      "Epoch 566/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7715\n",
      "Epoch 567/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.7117\n",
      "Epoch 568/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.8920\n",
      "Epoch 569/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7791\n",
      "Epoch 570/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.8078\n",
      "Epoch 571/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.9071\n",
      "Epoch 572/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7804\n",
      "Epoch 573/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.8421\n",
      "Epoch 574/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.8083\n",
      "Epoch 575/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.8055\n",
      "Epoch 576/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.8917\n",
      "Epoch 577/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7996\n",
      "Epoch 578/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.7942\n",
      "Epoch 579/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.8948\n",
      "Epoch 580/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.8473\n",
      "Epoch 581/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7240\n",
      "Epoch 582/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7129\n",
      "Epoch 583/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.7802\n",
      "Epoch 584/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.9164\n",
      "Epoch 585/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.8761\n",
      "Epoch 586/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.7465\n",
      "Epoch 587/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.8150\n",
      "Epoch 588/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.7793\n",
      "Epoch 589/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.6701\n",
      "Epoch 590/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7565\n",
      "Epoch 591/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.7769\n",
      "Epoch 592/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7106\n",
      "Epoch 593/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7823\n",
      "Epoch 594/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.8087\n",
      "Epoch 595/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6610\n",
      "Epoch 596/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7553\n",
      "Epoch 597/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.8260\n",
      "Epoch 598/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8054\n",
      "Epoch 599/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7500\n",
      "Epoch 600/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.8676\n",
      "Epoch 601/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7204\n",
      "Epoch 602/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.8119\n",
      "Epoch 603/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.9075\n",
      "Epoch 604/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.8140\n",
      "Epoch 605/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.8275\n",
      "Epoch 606/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.7470\n",
      "Epoch 607/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8614\n",
      "Epoch 608/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5568 - accuracy: 0.8609\n",
      "Epoch 609/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.8534\n",
      "Epoch 610/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.7436\n",
      "Epoch 611/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.7433\n",
      "Epoch 612/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7326\n",
      "Epoch 613/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7953\n",
      "Epoch 614/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.8580\n",
      "Epoch 615/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7829\n",
      "Epoch 616/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.8359\n",
      "Epoch 617/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5601 - accuracy: 0.7143\n",
      "Epoch 618/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.7528\n",
      "Epoch 619/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7584\n",
      "Epoch 620/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.8396\n",
      "Epoch 621/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.7505\n",
      "Epoch 622/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.8820\n",
      "Epoch 623/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.7793\n",
      "Epoch 624/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.6581\n",
      "Epoch 625/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.8335\n",
      "Epoch 626/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.8020\n",
      "Epoch 627/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.7363\n",
      "Epoch 628/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.8022\n",
      "Epoch 629/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.9351\n",
      "Epoch 630/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.8235\n",
      "Epoch 631/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.8076\n",
      "Epoch 632/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.8674\n",
      "Epoch 633/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7683\n",
      "Epoch 634/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.9025\n",
      "Epoch 635/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.8516\n",
      "Epoch 636/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.8326\n",
      "Epoch 637/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.8523\n",
      "Epoch 638/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.8089\n",
      "Epoch 639/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.8764\n",
      "Epoch 640/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.6861\n",
      "Epoch 641/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.8306\n",
      "Epoch 642/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.8326\n",
      "Epoch 643/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.8463\n",
      "Epoch 644/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7924\n",
      "Epoch 645/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7822\n",
      "Epoch 646/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.9238\n",
      "Epoch 647/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7027\n",
      "Epoch 648/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.8329\n",
      "Epoch 649/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8249\n",
      "Epoch 650/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7822\n",
      "Epoch 651/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.8435\n",
      "Epoch 652/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6986\n",
      "Epoch 653/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.8771\n",
      "Epoch 654/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7393\n",
      "Epoch 655/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.7723\n",
      "Epoch 656/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7247\n",
      "Epoch 657/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.9307\n",
      "Epoch 658/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.8055\n",
      "Epoch 659/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.8023\n",
      "Epoch 660/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.8311\n",
      "Epoch 661/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.8748\n",
      "Epoch 662/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.8403\n",
      "Epoch 663/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.8419\n",
      "Epoch 664/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7373\n",
      "Epoch 665/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.8166\n",
      "Epoch 666/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.7462\n",
      "Epoch 667/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.6913\n",
      "Epoch 668/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.8395\n",
      "Epoch 669/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.7669\n",
      "Epoch 670/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7294\n",
      "Epoch 671/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5414 - accuracy: 0.9092\n",
      "Epoch 672/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.8442\n",
      "Epoch 673/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.6837\n",
      "Epoch 674/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7977\n",
      "Epoch 675/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.8197\n",
      "Epoch 676/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.8871\n",
      "Epoch 677/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.8627\n",
      "Epoch 678/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5964 - accuracy: 0.7766\n",
      "Epoch 679/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.8899\n",
      "Epoch 680/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.7725\n",
      "Epoch 681/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.8368\n",
      "Epoch 682/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.9152\n",
      "Epoch 683/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.8572\n",
      "Epoch 684/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.8903\n",
      "Epoch 685/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.8114\n",
      "Epoch 686/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.8367\n",
      "Epoch 687/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.8269\n",
      "Epoch 688/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.7246\n",
      "Epoch 689/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5465 - accuracy: 0.8650\n",
      "Epoch 690/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7671\n",
      "Epoch 691/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7857\n",
      "Epoch 692/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5536 - accuracy: 0.8572\n",
      "Epoch 693/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.8371\n",
      "Epoch 694/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.6835\n",
      "Epoch 695/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.8134\n",
      "Epoch 696/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.8599\n",
      "Epoch 697/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.8210\n",
      "Epoch 698/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7803\n",
      "Epoch 699/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5627 - accuracy: 0.7266\n",
      "Epoch 700/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.9565\n",
      "Epoch 701/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.6958\n",
      "Epoch 702/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7419\n",
      "Epoch 703/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.8162\n",
      "Epoch 704/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.8273\n",
      "Epoch 705/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7690\n",
      "Epoch 706/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5946 - accuracy: 0.7537\n",
      "Epoch 707/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7271\n",
      "Epoch 708/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.8204\n",
      "Epoch 709/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.8146\n",
      "Epoch 710/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7378\n",
      "Epoch 711/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.8343\n",
      "Epoch 712/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5865 - accuracy: 0.8122\n",
      "Epoch 713/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7734\n",
      "Epoch 714/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.8649\n",
      "Epoch 715/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.8370\n",
      "Epoch 716/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.9027\n",
      "Epoch 717/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.8392\n",
      "Epoch 718/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.8149\n",
      "Epoch 719/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7850\n",
      "Epoch 720/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7797\n",
      "Epoch 721/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7340\n",
      "Epoch 722/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.8249\n",
      "Epoch 723/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7384\n",
      "Epoch 724/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6655\n",
      "Epoch 725/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7768\n",
      "Epoch 726/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.7634\n",
      "Epoch 727/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7682\n",
      "Epoch 728/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.8199\n",
      "Epoch 729/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.8221\n",
      "Epoch 730/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.7477\n",
      "Epoch 731/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5464 - accuracy: 0.8208\n",
      "Epoch 732/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8600\n",
      "Epoch 733/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.9012\n",
      "Epoch 734/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7528\n",
      "Epoch 735/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.8168\n",
      "Epoch 736/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.8940\n",
      "Epoch 737/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.7761\n",
      "Epoch 738/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.9030\n",
      "Epoch 739/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.8414\n",
      "Epoch 740/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.7368\n",
      "Epoch 741/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.7902\n",
      "Epoch 742/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7497\n",
      "Epoch 743/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.8452\n",
      "Epoch 744/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8433\n",
      "Epoch 745/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.8422\n",
      "Epoch 746/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.8185\n",
      "Epoch 747/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7954\n",
      "Epoch 748/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.8660\n",
      "Epoch 749/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7469\n",
      "Epoch 750/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7637\n",
      "Epoch 751/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7324\n",
      "Epoch 752/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.8394\n",
      "Epoch 753/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.8029\n",
      "Epoch 754/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.8306\n",
      "Epoch 755/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.7969\n",
      "Epoch 756/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.9093\n",
      "Epoch 757/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8512\n",
      "Epoch 758/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.8254\n",
      "Epoch 759/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7854\n",
      "Epoch 760/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.8257\n",
      "Epoch 761/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.9201\n",
      "Epoch 762/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5541 - accuracy: 0.8092\n",
      "Epoch 763/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7391\n",
      "Epoch 764/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.7116\n",
      "Epoch 765/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.7496\n",
      "Epoch 766/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.8616\n",
      "Epoch 767/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.8167\n",
      "Epoch 768/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7782\n",
      "Epoch 769/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5409 - accuracy: 0.7792\n",
      "Epoch 770/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.9115\n",
      "Epoch 771/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.9046\n",
      "Epoch 772/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5685 - accuracy: 0.7821\n",
      "Epoch 773/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5240 - accuracy: 0.9408\n",
      "Epoch 774/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7281\n",
      "Epoch 775/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7884\n",
      "Epoch 776/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5501 - accuracy: 0.8350\n",
      "Epoch 777/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.8196\n",
      "Epoch 778/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.8799\n",
      "Epoch 779/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7608\n",
      "Epoch 780/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.8058\n",
      "Epoch 781/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.8017\n",
      "Epoch 782/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8346\n",
      "Epoch 783/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7004\n",
      "Epoch 784/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.7577\n",
      "Epoch 785/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.8351\n",
      "Epoch 786/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8481\n",
      "Epoch 787/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.8246\n",
      "Epoch 788/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.8255\n",
      "Epoch 789/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.8351\n",
      "Epoch 790/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8100\n",
      "Epoch 791/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.7580\n",
      "Epoch 792/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.8469\n",
      "Epoch 793/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8239\n",
      "Epoch 794/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5394 - accuracy: 0.7901\n",
      "Epoch 795/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7936\n",
      "Epoch 796/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.8450\n",
      "Epoch 797/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.6769\n",
      "Epoch 798/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7911\n",
      "Epoch 799/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.8042\n",
      "Epoch 800/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7286\n",
      "Epoch 801/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7508\n",
      "Epoch 802/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8614\n",
      "Epoch 803/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.8467\n",
      "Epoch 804/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7529\n",
      "Epoch 805/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8428\n",
      "Epoch 806/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.8074\n",
      "Epoch 807/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.8810\n",
      "Epoch 808/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7383\n",
      "Epoch 809/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.7298\n",
      "Epoch 810/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.8837\n",
      "Epoch 811/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.8063\n",
      "Epoch 812/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.8895\n",
      "Epoch 813/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.8781\n",
      "Epoch 814/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7902\n",
      "Epoch 815/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.8589\n",
      "Epoch 816/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.8432\n",
      "Epoch 817/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5287 - accuracy: 0.8633\n",
      "Epoch 818/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.7515\n",
      "Epoch 819/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.8067\n",
      "Epoch 820/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.8151\n",
      "Epoch 821/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.8806\n",
      "Epoch 822/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5447 - accuracy: 0.8649\n",
      "Epoch 823/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7759\n",
      "Epoch 824/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.9140\n",
      "Epoch 825/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5609 - accuracy: 0.7211\n",
      "Epoch 826/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7752\n",
      "Epoch 827/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.7765\n",
      "Epoch 828/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8989\n",
      "Epoch 829/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.8165\n",
      "Epoch 830/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7868\n",
      "Epoch 831/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.8323\n",
      "Epoch 832/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.7899\n",
      "Epoch 833/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7329\n",
      "Epoch 834/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.8179\n",
      "Epoch 835/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6010 - accuracy: 0.6620\n",
      "Epoch 836/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.8607\n",
      "Epoch 837/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.8102\n",
      "Epoch 838/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7641\n",
      "Epoch 839/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7551\n",
      "Epoch 840/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.9320\n",
      "Epoch 841/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.9143\n",
      "Epoch 842/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.8497\n",
      "Epoch 843/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7304\n",
      "Epoch 844/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5546 - accuracy: 0.8937\n",
      "Epoch 845/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.8773\n",
      "Epoch 846/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5544 - accuracy: 0.7964\n",
      "Epoch 847/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7765\n",
      "Epoch 848/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5565 - accuracy: 0.8116\n",
      "Epoch 849/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.7555\n",
      "Epoch 850/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7707\n",
      "Epoch 851/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.8034\n",
      "Epoch 852/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7279\n",
      "Epoch 853/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.8442\n",
      "Epoch 854/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.8586\n",
      "Epoch 855/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.8811\n",
      "Epoch 856/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.8357\n",
      "Epoch 857/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.8257\n",
      "Epoch 858/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.8535\n",
      "Epoch 859/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.8483\n",
      "Epoch 860/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.6481\n",
      "Epoch 861/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7494\n",
      "Epoch 862/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.8005\n",
      "Epoch 863/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.6850\n",
      "Epoch 864/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.8434\n",
      "Epoch 865/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7094\n",
      "Epoch 866/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.7198\n",
      "Epoch 867/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.8034\n",
      "Epoch 868/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.8464\n",
      "Epoch 869/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.9029\n",
      "Epoch 870/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7857\n",
      "Epoch 871/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7792\n",
      "Epoch 872/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.7625\n",
      "Epoch 873/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5743 - accuracy: 0.7762\n",
      "Epoch 874/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6069 - accuracy: 0.6440\n",
      "Epoch 875/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.8175\n",
      "Epoch 876/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.8664\n",
      "Epoch 877/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6038 - accuracy: 0.7673\n",
      "Epoch 878/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.7228\n",
      "Epoch 879/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7036\n",
      "Epoch 880/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.8192\n",
      "Epoch 881/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.7169\n",
      "Epoch 882/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.8808\n",
      "Epoch 883/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.8345\n",
      "Epoch 884/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7900\n",
      "Epoch 885/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.8814\n",
      "Epoch 886/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6010 - accuracy: 0.8006\n",
      "Epoch 887/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.8361\n",
      "Epoch 888/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5157 - accuracy: 0.8866\n",
      "Epoch 889/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7369\n",
      "Epoch 890/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.9071\n",
      "Epoch 891/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.8730\n",
      "Epoch 892/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.8323\n",
      "Epoch 893/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.7972\n",
      "Epoch 894/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.8394\n",
      "Epoch 895/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.8455\n",
      "Epoch 896/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.8010\n",
      "Epoch 897/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5507 - accuracy: 0.7951\n",
      "Epoch 898/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.8414\n",
      "Epoch 899/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7767\n",
      "Epoch 900/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.6768\n",
      "Epoch 901/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7420\n",
      "Epoch 902/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7793\n",
      "Epoch 903/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.7859\n",
      "Epoch 904/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.8556\n",
      "Epoch 905/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.6772\n",
      "Epoch 906/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.8908\n",
      "Epoch 907/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.7976\n",
      "Epoch 908/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.8698\n",
      "Epoch 909/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.8418\n",
      "Epoch 910/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.9060\n",
      "Epoch 911/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.7487\n",
      "Epoch 912/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.8523\n",
      "Epoch 913/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.8090\n",
      "Epoch 914/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.9348\n",
      "Epoch 915/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.9158\n",
      "Epoch 916/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.9340\n",
      "Epoch 917/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.8828\n",
      "Epoch 918/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.9210\n",
      "Epoch 919/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.8749\n",
      "Epoch 920/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7988\n",
      "Epoch 921/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.9220\n",
      "Epoch 922/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.8233\n",
      "Epoch 923/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.6839\n",
      "Epoch 924/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5680 - accuracy: 0.8121\n",
      "Epoch 925/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.8465\n",
      "Epoch 926/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5206 - accuracy: 0.8957\n",
      "Epoch 927/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7994\n",
      "Epoch 928/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.8470\n",
      "Epoch 929/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7811\n",
      "Epoch 930/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.8300\n",
      "Epoch 931/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7178\n",
      "Epoch 932/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.8408\n",
      "Epoch 933/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.8508\n",
      "Epoch 934/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.8376\n",
      "Epoch 935/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5822 - accuracy: 0.7643\n",
      "Epoch 936/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7867\n",
      "Epoch 937/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.8500\n",
      "Epoch 938/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.8038\n",
      "Epoch 939/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.8442\n",
      "Epoch 940/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.8216\n",
      "Epoch 941/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7482\n",
      "Epoch 942/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.6759\n",
      "Epoch 943/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.8760\n",
      "Epoch 944/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.8776\n",
      "Epoch 945/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.9457\n",
      "Epoch 946/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7675\n",
      "Epoch 947/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.8187\n",
      "Epoch 948/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7005\n",
      "Epoch 949/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.8857\n",
      "Epoch 950/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7728\n",
      "Epoch 951/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.6616\n",
      "Epoch 952/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.8176\n",
      "Epoch 953/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.8436\n",
      "Epoch 954/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.9302\n",
      "Epoch 955/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8674\n",
      "Epoch 956/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.8087\n",
      "Epoch 957/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7600\n",
      "Epoch 958/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7872\n",
      "Epoch 959/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5616 - accuracy: 0.8570\n",
      "Epoch 960/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7533\n",
      "Epoch 961/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8092\n",
      "Epoch 962/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.7709\n",
      "Epoch 963/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.8839\n",
      "Epoch 964/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.9061\n",
      "Epoch 965/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8051\n",
      "Epoch 966/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.8390\n",
      "Epoch 967/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7227\n",
      "Epoch 968/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.8000\n",
      "Epoch 969/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.8300\n",
      "Epoch 970/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.8710\n",
      "Epoch 971/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.8028\n",
      "Epoch 972/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.8597\n",
      "Epoch 973/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7513\n",
      "Epoch 974/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.7060\n",
      "Epoch 975/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.8867\n",
      "Epoch 976/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.8387\n",
      "Epoch 977/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.8434\n",
      "Epoch 978/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.8511\n",
      "Epoch 979/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.8253\n",
      "Epoch 980/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.8614\n",
      "Epoch 981/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7707\n",
      "Epoch 982/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.7757\n",
      "Epoch 983/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7967\n",
      "Epoch 984/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5985 - accuracy: 0.6848\n",
      "Epoch 985/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5786 - accuracy: 0.9384\n",
      "Epoch 986/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5687 - accuracy: 0.8554\n",
      "Epoch 987/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.8597\n",
      "Epoch 988/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5801 - accuracy: 0.7031\n",
      "Epoch 989/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5186 - accuracy: 0.8505\n",
      "Epoch 990/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7956\n",
      "Epoch 991/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.7777\n",
      "Epoch 992/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5543 - accuracy: 0.7938\n",
      "Epoch 993/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7917\n",
      "Epoch 994/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.7366\n",
      "Epoch 995/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.8118\n",
      "Epoch 996/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.8404\n",
      "Epoch 997/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.8205\n",
      "Epoch 998/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8973\n",
      "Epoch 999/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.8835\n",
      "Epoch 1000/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5590 - accuracy: 0.7721\n",
      "Epoch 1001/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6577\n",
      "Epoch 1002/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.8037\n",
      "Epoch 1003/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5819 - accuracy: 0.8044\n",
      "Epoch 1004/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.7601\n",
      "Epoch 1005/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7744\n",
      "Epoch 1006/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7629\n",
      "Epoch 1007/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.8198\n",
      "Epoch 1008/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.8891\n",
      "Epoch 1009/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.7468\n",
      "Epoch 1010/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5666 - accuracy: 0.8187\n",
      "Epoch 1011/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5192 - accuracy: 0.9073\n",
      "Epoch 1012/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.8926\n",
      "Epoch 1013/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.8087\n",
      "Epoch 1014/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.8838\n",
      "Epoch 1015/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.8300\n",
      "Epoch 1016/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.8983\n",
      "Epoch 1017/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7686\n",
      "Epoch 1018/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7760\n",
      "Epoch 1019/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.8643\n",
      "Epoch 1020/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.8405\n",
      "Epoch 1021/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.8851\n",
      "Epoch 1022/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.7394\n",
      "Epoch 1023/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.9633\n",
      "Epoch 1024/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7859\n",
      "Epoch 1025/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.8537\n",
      "Epoch 1026/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.8886\n",
      "Epoch 1027/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7640\n",
      "Epoch 1028/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.7790\n",
      "Epoch 1029/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.8089\n",
      "Epoch 1030/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.8750\n",
      "Epoch 1031/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.7723\n",
      "Epoch 1032/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.8796\n",
      "Epoch 1033/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.7930\n",
      "Epoch 1034/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.8021\n",
      "Epoch 1035/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7349\n",
      "Epoch 1036/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.8745\n",
      "Epoch 1037/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7978\n",
      "Epoch 1038/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.7064\n",
      "Epoch 1039/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7991\n",
      "Epoch 1040/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.9164\n",
      "Epoch 1041/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.8277\n",
      "Epoch 1042/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.8871\n",
      "Epoch 1043/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8197\n",
      "Epoch 1044/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.7053\n",
      "Epoch 1045/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7218\n",
      "Epoch 1046/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8374\n",
      "Epoch 1047/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.6589\n",
      "Epoch 1048/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.9673\n",
      "Epoch 1049/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7926\n",
      "Epoch 1050/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.8001\n",
      "Epoch 1051/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.8852\n",
      "Epoch 1052/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.8818\n",
      "Epoch 1053/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.7664\n",
      "Epoch 1054/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.7564\n",
      "Epoch 1055/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7808\n",
      "Epoch 1056/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.8243\n",
      "Epoch 1057/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.8591\n",
      "Epoch 1058/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7833\n",
      "Epoch 1059/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.8651\n",
      "Epoch 1060/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.8390\n",
      "Epoch 1061/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6096\n",
      "Epoch 1062/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.6626\n",
      "Epoch 1063/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.7634\n",
      "Epoch 1064/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.8698\n",
      "Epoch 1065/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.8333\n",
      "Epoch 1066/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5387 - accuracy: 0.9069\n",
      "Epoch 1067/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.9093\n",
      "Epoch 1068/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.9000\n",
      "Epoch 1069/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.7617\n",
      "Epoch 1070/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7639\n",
      "Epoch 1071/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.7917\n",
      "Epoch 1072/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.8153\n",
      "Epoch 1073/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7373\n",
      "Epoch 1074/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.8371\n",
      "Epoch 1075/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.8137\n",
      "Epoch 1076/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7458\n",
      "Epoch 1077/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8069\n",
      "Epoch 1078/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.8217\n",
      "Epoch 1079/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5293 - accuracy: 0.8584\n",
      "Epoch 1080/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.8688\n",
      "Epoch 1081/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5706 - accuracy: 0.8871\n",
      "Epoch 1082/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.8118\n",
      "Epoch 1083/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7444\n",
      "Epoch 1084/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.8062\n",
      "Epoch 1085/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7732\n",
      "Epoch 1086/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.8053\n",
      "Epoch 1087/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.8896\n",
      "Epoch 1088/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.8722\n",
      "Epoch 1089/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.7896\n",
      "Epoch 1090/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.8479\n",
      "Epoch 1091/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.7687\n",
      "Epoch 1092/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5274 - accuracy: 0.8822\n",
      "Epoch 1093/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7320\n",
      "Epoch 1094/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.8675\n",
      "Epoch 1095/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.8479\n",
      "Epoch 1096/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.8248\n",
      "Epoch 1097/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.7449\n",
      "Epoch 1098/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7897\n",
      "Epoch 1099/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7035\n",
      "Epoch 1100/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.8779\n",
      "Epoch 1101/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.7685\n",
      "Epoch 1102/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.8057\n",
      "Epoch 1103/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.8179\n",
      "Epoch 1104/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.8702\n",
      "Epoch 1105/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.8509\n",
      "Epoch 1106/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5262 - accuracy: 0.8414\n",
      "Epoch 1107/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.8084\n",
      "Epoch 1108/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5785 - accuracy: 0.7613\n",
      "Epoch 1109/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.8378\n",
      "Epoch 1110/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.8092\n",
      "Epoch 1111/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7807\n",
      "Epoch 1112/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.8594\n",
      "Epoch 1113/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.8838\n",
      "Epoch 1114/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7529\n",
      "Epoch 1115/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7789\n",
      "Epoch 1116/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5345 - accuracy: 0.8119\n",
      "Epoch 1117/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.8295\n",
      "Epoch 1118/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7947\n",
      "Epoch 1119/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8574\n",
      "Epoch 1120/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.8568\n",
      "Epoch 1121/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.8774\n",
      "Epoch 1122/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5241 - accuracy: 0.8632\n",
      "Epoch 1123/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.7494\n",
      "Epoch 1124/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.8110\n",
      "Epoch 1125/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7935\n",
      "Epoch 1126/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.8091\n",
      "Epoch 1127/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5461 - accuracy: 0.9084\n",
      "Epoch 1128/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.8331\n",
      "Epoch 1129/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.8750\n",
      "Epoch 1130/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.8655\n",
      "Epoch 1131/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.6835\n",
      "Epoch 1132/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.8498\n",
      "Epoch 1133/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.7868\n",
      "Epoch 1134/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7985\n",
      "Epoch 1135/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7678\n",
      "Epoch 1136/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7407\n",
      "Epoch 1137/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7407\n",
      "Epoch 1138/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.9123\n",
      "Epoch 1139/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.7598\n",
      "Epoch 1140/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7525\n",
      "Epoch 1141/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.7947\n",
      "Epoch 1142/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5460 - accuracy: 0.8246\n",
      "Epoch 1143/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7823\n",
      "Epoch 1144/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7523\n",
      "Epoch 1145/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.8815\n",
      "Epoch 1146/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.8490\n",
      "Epoch 1147/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.8656\n",
      "Epoch 1148/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.8190\n",
      "Epoch 1149/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.8821\n",
      "Epoch 1150/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7857\n",
      "Epoch 1151/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.8396\n",
      "Epoch 1152/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5762 - accuracy: 0.7816\n",
      "Epoch 1153/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7954\n",
      "Epoch 1154/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.9080\n",
      "Epoch 1155/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.7218\n",
      "Epoch 1156/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.8034\n",
      "Epoch 1157/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.8194\n",
      "Epoch 1158/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5825 - accuracy: 0.7790\n",
      "Epoch 1159/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7205\n",
      "Epoch 1160/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.8662\n",
      "Epoch 1161/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.8394\n",
      "Epoch 1162/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.7638\n",
      "Epoch 1163/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.8136\n",
      "Epoch 1164/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.8493\n",
      "Epoch 1165/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.8139\n",
      "Epoch 1166/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6182 - accuracy: 0.6970\n",
      "Epoch 1167/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.8575\n",
      "Epoch 1168/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.8169\n",
      "Epoch 1169/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7493\n",
      "Epoch 1170/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.8798\n",
      "Epoch 1171/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.6930\n",
      "Epoch 1172/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7500\n",
      "Epoch 1173/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7745\n",
      "Epoch 1174/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.8817\n",
      "Epoch 1175/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.8244\n",
      "Epoch 1176/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7310\n",
      "Epoch 1177/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.8606\n",
      "Epoch 1178/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7617\n",
      "Epoch 1179/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7565\n",
      "Epoch 1180/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.8392\n",
      "Epoch 1181/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.6993\n",
      "Epoch 1182/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.7662\n",
      "Epoch 1183/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.8521\n",
      "Epoch 1184/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.8352\n",
      "Epoch 1185/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.7678\n",
      "Epoch 1186/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.9035\n",
      "Epoch 1187/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5809 - accuracy: 0.7718\n",
      "Epoch 1188/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.8023\n",
      "Epoch 1189/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6721\n",
      "Epoch 1190/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7999\n",
      "Epoch 1191/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.8211\n",
      "Epoch 1192/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.8263\n",
      "Epoch 1193/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.8530\n",
      "Epoch 1194/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.8372\n",
      "Epoch 1195/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5317 - accuracy: 0.8393\n",
      "Epoch 1196/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.9021\n",
      "Epoch 1197/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.8235\n",
      "Epoch 1198/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.9343\n",
      "Epoch 1199/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.8604\n",
      "Epoch 1200/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.8441\n",
      "Epoch 1201/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7368\n",
      "Epoch 1202/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5484 - accuracy: 0.8834\n",
      "Epoch 1203/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5849 - accuracy: 0.8131\n",
      "Epoch 1204/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.8244\n",
      "Epoch 1205/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.7873\n",
      "Epoch 1206/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7567\n",
      "Epoch 1207/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7526\n",
      "Epoch 1208/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.8588\n",
      "Epoch 1209/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.8835\n",
      "Epoch 1210/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.8774\n",
      "Epoch 1211/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.9030\n",
      "Epoch 1212/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.6755\n",
      "Epoch 1213/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.6970\n",
      "Epoch 1214/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.8185\n",
      "Epoch 1215/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8502\n",
      "Epoch 1216/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7767\n",
      "Epoch 1217/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.7765\n",
      "Epoch 1218/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.7001\n",
      "Epoch 1219/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.8039\n",
      "Epoch 1220/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8621\n",
      "Epoch 1221/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.9104\n",
      "Epoch 1222/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.8873\n",
      "Epoch 1223/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.8397\n",
      "Epoch 1224/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.8047\n",
      "Epoch 1225/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8112\n",
      "Epoch 1226/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7863\n",
      "Epoch 1227/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.7640\n",
      "Epoch 1228/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.6808\n",
      "Epoch 1229/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.8457\n",
      "Epoch 1230/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7965\n",
      "Epoch 1231/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.6525\n",
      "Epoch 1232/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.7597\n",
      "Epoch 1233/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.8386\n",
      "Epoch 1234/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8446\n",
      "Epoch 1235/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.8990\n",
      "Epoch 1236/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.9862\n",
      "Epoch 1237/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8191\n",
      "Epoch 1238/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.8020\n",
      "Epoch 1239/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.8569\n",
      "Epoch 1240/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8837\n",
      "Epoch 1241/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.7854\n",
      "Epoch 1242/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.8169\n",
      "Epoch 1243/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.8956\n",
      "Epoch 1244/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.8611\n",
      "Epoch 1245/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.9271\n",
      "Epoch 1246/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.9053\n",
      "Epoch 1247/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7966\n",
      "Epoch 1248/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.8859\n",
      "Epoch 1249/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.8041\n",
      "Epoch 1250/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7094\n",
      "Epoch 1251/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7475\n",
      "Epoch 1252/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7927\n",
      "Epoch 1253/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.8741\n",
      "Epoch 1254/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.8375\n",
      "Epoch 1255/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7714\n",
      "Epoch 1256/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7764\n",
      "Epoch 1257/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5795 - accuracy: 0.8270\n",
      "Epoch 1258/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6059 - accuracy: 0.7575\n",
      "Epoch 1259/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5577 - accuracy: 0.7809\n",
      "Epoch 1260/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.8833\n",
      "Epoch 1261/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5538 - accuracy: 0.8378\n",
      "Epoch 1262/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7827\n",
      "Epoch 1263/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.8450\n",
      "Epoch 1264/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.8620\n",
      "Epoch 1265/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.7858\n",
      "Epoch 1266/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5592 - accuracy: 0.8939\n",
      "Epoch 1267/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.8865\n",
      "Epoch 1268/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8768\n",
      "Epoch 1269/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.8282\n",
      "Epoch 1270/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.8401\n",
      "Epoch 1271/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7974\n",
      "Epoch 1272/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7147\n",
      "Epoch 1273/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5606 - accuracy: 0.7907\n",
      "Epoch 1274/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5458 - accuracy: 0.7637\n",
      "Epoch 1275/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5534 - accuracy: 0.8818\n",
      "Epoch 1276/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.8455\n",
      "Epoch 1277/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.7558\n",
      "Epoch 1278/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.8567\n",
      "Epoch 1279/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.7958\n",
      "Epoch 1280/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5830 - accuracy: 0.7544\n",
      "Epoch 1281/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5660 - accuracy: 0.7960\n",
      "Epoch 1282/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.7629\n",
      "Epoch 1283/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.8070\n",
      "Epoch 1284/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.7237\n",
      "Epoch 1285/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7256\n",
      "Epoch 1286/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.8954\n",
      "Epoch 1287/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.8646\n",
      "Epoch 1288/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.7017\n",
      "Epoch 1289/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.8491\n",
      "Epoch 1290/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.7301\n",
      "Epoch 1291/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.8124\n",
      "Epoch 1292/2000\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5706 - accuracy: 0.7587\n",
      "Epoch 1293/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.8667\n",
      "Epoch 1294/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.8164\n",
      "Epoch 1295/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.8572\n",
      "Epoch 1296/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.7018\n",
      "Epoch 1297/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7202\n",
      "Epoch 1298/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.8275\n",
      "Epoch 1299/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7653\n",
      "Epoch 1300/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8131\n",
      "Epoch 1301/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.8391\n",
      "Epoch 1302/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.9046\n",
      "Epoch 1303/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7118\n",
      "Epoch 1304/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.9135\n",
      "Epoch 1305/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8193\n",
      "Epoch 1306/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.7872\n",
      "Epoch 1307/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.8828\n",
      "Epoch 1308/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.8203\n",
      "Epoch 1309/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5757 - accuracy: 0.8213\n",
      "Epoch 1310/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.8316\n",
      "Epoch 1311/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.9731\n",
      "Epoch 1312/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.8502\n",
      "Epoch 1313/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8515\n",
      "Epoch 1314/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.8482\n",
      "Epoch 1315/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.9119\n",
      "Epoch 1316/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.8559\n",
      "Epoch 1317/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.9023\n",
      "Epoch 1318/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.8126\n",
      "Epoch 1319/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.6971\n",
      "Epoch 1320/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.8648\n",
      "Epoch 1321/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.8518\n",
      "Epoch 1322/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.8264\n",
      "Epoch 1323/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.8544\n",
      "Epoch 1324/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6816\n",
      "Epoch 1325/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6314\n",
      "Epoch 1326/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.8458\n",
      "Epoch 1327/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7830\n",
      "Epoch 1328/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.8395\n",
      "Epoch 1329/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.7987\n",
      "Epoch 1330/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6910\n",
      "Epoch 1331/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5733 - accuracy: 0.7332\n",
      "Epoch 1332/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5692 - accuracy: 0.7023\n",
      "Epoch 1333/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.8546\n",
      "Epoch 1334/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.8066\n",
      "Epoch 1335/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.7977\n",
      "Epoch 1336/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.8399\n",
      "Epoch 1337/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.8482\n",
      "Epoch 1338/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.8267\n",
      "Epoch 1339/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.8201\n",
      "Epoch 1340/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.9211\n",
      "Epoch 1341/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.8927\n",
      "Epoch 1342/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.8257\n",
      "Epoch 1343/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7777\n",
      "Epoch 1344/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6735\n",
      "Epoch 1345/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.8604\n",
      "Epoch 1346/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.9843\n",
      "Epoch 1347/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7287\n",
      "Epoch 1348/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7868\n",
      "Epoch 1349/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7998\n",
      "Epoch 1350/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.8552\n",
      "Epoch 1351/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.8204\n",
      "Epoch 1352/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.8305\n",
      "Epoch 1353/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.7458\n",
      "Epoch 1354/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.8060\n",
      "Epoch 1355/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.9051\n",
      "Epoch 1356/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.8060\n",
      "Epoch 1357/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.8237\n",
      "Epoch 1358/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.8749\n",
      "Epoch 1359/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7501\n",
      "Epoch 1360/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.8431\n",
      "Epoch 1361/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7467\n",
      "Epoch 1362/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5660 - accuracy: 0.7718\n",
      "Epoch 1363/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.9570\n",
      "Epoch 1364/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.8707\n",
      "Epoch 1365/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8176\n",
      "Epoch 1366/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5874 - accuracy: 0.7764\n",
      "Epoch 1367/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8197\n",
      "Epoch 1368/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5411 - accuracy: 0.8699\n",
      "Epoch 1369/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7064\n",
      "Epoch 1370/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7803\n",
      "Epoch 1371/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.9218\n",
      "Epoch 1372/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.8622\n",
      "Epoch 1373/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.8216\n",
      "Epoch 1374/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7947\n",
      "Epoch 1375/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.8102\n",
      "Epoch 1376/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7963\n",
      "Epoch 1377/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.7931\n",
      "Epoch 1378/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.8842\n",
      "Epoch 1379/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.8407\n",
      "Epoch 1380/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.8639\n",
      "Epoch 1381/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7497\n",
      "Epoch 1382/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.8245\n",
      "Epoch 1383/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7478\n",
      "Epoch 1384/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7207\n",
      "Epoch 1385/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6097\n",
      "Epoch 1386/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7142\n",
      "Epoch 1387/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8887\n",
      "Epoch 1388/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.8115\n",
      "Epoch 1389/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.8181\n",
      "Epoch 1390/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.9023\n",
      "Epoch 1391/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.8380\n",
      "Epoch 1392/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.7219\n",
      "Epoch 1393/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.6861\n",
      "Epoch 1394/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.9366\n",
      "Epoch 1395/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8726\n",
      "Epoch 1396/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.8622\n",
      "Epoch 1397/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7463\n",
      "Epoch 1398/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7952\n",
      "Epoch 1399/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.8762\n",
      "Epoch 1400/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.8206\n",
      "Epoch 1401/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.7200\n",
      "Epoch 1402/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8011\n",
      "Epoch 1403/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.8671\n",
      "Epoch 1404/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.8235\n",
      "Epoch 1405/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7493\n",
      "Epoch 1406/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.8271\n",
      "Epoch 1407/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.8504\n",
      "Epoch 1408/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5959 - accuracy: 0.8031\n",
      "Epoch 1409/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.8067\n",
      "Epoch 1410/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.8985\n",
      "Epoch 1411/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.8581\n",
      "Epoch 1412/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.7979\n",
      "Epoch 1413/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.8544\n",
      "Epoch 1414/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.8921\n",
      "Epoch 1415/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.8352\n",
      "Epoch 1416/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5850 - accuracy: 0.7212\n",
      "Epoch 1417/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7706\n",
      "Epoch 1418/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.9213\n",
      "Epoch 1419/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.9007\n",
      "Epoch 1420/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.8821\n",
      "Epoch 1421/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6144 - accuracy: 0.6847\n",
      "Epoch 1422/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.7579\n",
      "Epoch 1423/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.8688\n",
      "Epoch 1424/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.7609\n",
      "Epoch 1425/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.9453\n",
      "Epoch 1426/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6900\n",
      "Epoch 1427/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.6932\n",
      "Epoch 1428/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.8945\n",
      "Epoch 1429/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.8400\n",
      "Epoch 1430/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.8231\n",
      "Epoch 1431/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.8341\n",
      "Epoch 1432/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7418\n",
      "Epoch 1433/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.8902\n",
      "Epoch 1434/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7981\n",
      "Epoch 1435/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8047\n",
      "Epoch 1436/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.8373\n",
      "Epoch 1437/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.7460\n",
      "Epoch 1438/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.8491\n",
      "Epoch 1439/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.9178\n",
      "Epoch 1440/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8909\n",
      "Epoch 1441/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6111 - accuracy: 0.6529\n",
      "Epoch 1442/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7966\n",
      "Epoch 1443/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.8022\n",
      "Epoch 1444/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.7288\n",
      "Epoch 1445/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.9116\n",
      "Epoch 1446/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.6063\n",
      "Epoch 1447/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7776\n",
      "Epoch 1448/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.8883\n",
      "Epoch 1449/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.7379\n",
      "Epoch 1450/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7655\n",
      "Epoch 1451/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.7627\n",
      "Epoch 1452/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.8016\n",
      "Epoch 1453/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.8303\n",
      "Epoch 1454/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.8527\n",
      "Epoch 1455/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.8095\n",
      "Epoch 1456/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.8537\n",
      "Epoch 1457/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.8336\n",
      "Epoch 1458/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7470\n",
      "Epoch 1459/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7964\n",
      "Epoch 1460/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.8056\n",
      "Epoch 1461/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.8101\n",
      "Epoch 1462/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7912\n",
      "Epoch 1463/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5704 - accuracy: 0.7492\n",
      "Epoch 1464/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7563\n",
      "Epoch 1465/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.8189\n",
      "Epoch 1466/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7446\n",
      "Epoch 1467/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7071\n",
      "Epoch 1468/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7489\n",
      "Epoch 1469/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.7486\n",
      "Epoch 1470/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.8530\n",
      "Epoch 1471/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7966\n",
      "Epoch 1472/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7802\n",
      "Epoch 1473/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.8281\n",
      "Epoch 1474/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7760\n",
      "Epoch 1475/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7417\n",
      "Epoch 1476/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.8529\n",
      "Epoch 1477/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.8442\n",
      "Epoch 1478/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.9212\n",
      "Epoch 1479/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7683\n",
      "Epoch 1480/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.8289\n",
      "Epoch 1481/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7884\n",
      "Epoch 1482/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.8218\n",
      "Epoch 1483/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.9141\n",
      "Epoch 1484/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7859\n",
      "Epoch 1485/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.8064\n",
      "Epoch 1486/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7920\n",
      "Epoch 1487/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.8455\n",
      "Epoch 1488/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.8610\n",
      "Epoch 1489/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6179\n",
      "Epoch 1490/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7513\n",
      "Epoch 1491/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7631\n",
      "Epoch 1492/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.8202\n",
      "Epoch 1493/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7613\n",
      "Epoch 1494/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.8551\n",
      "Epoch 1495/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8738\n",
      "Epoch 1496/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8601\n",
      "Epoch 1497/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7301\n",
      "Epoch 1498/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7653\n",
      "Epoch 1499/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8362\n",
      "Epoch 1500/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.6801\n",
      "Epoch 1501/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6011 - accuracy: 0.7380\n",
      "Epoch 1502/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7968\n",
      "Epoch 1503/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.9215\n",
      "Epoch 1504/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.8163\n",
      "Epoch 1505/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.8650\n",
      "Epoch 1506/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.8761\n",
      "Epoch 1507/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.8332\n",
      "Epoch 1508/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7277\n",
      "Epoch 1509/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.7629\n",
      "Epoch 1510/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7791\n",
      "Epoch 1511/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.9089\n",
      "Epoch 1512/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.8182\n",
      "Epoch 1513/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.8899\n",
      "Epoch 1514/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.9169\n",
      "Epoch 1515/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7999\n",
      "Epoch 1516/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.8629\n",
      "Epoch 1517/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.8275\n",
      "Epoch 1518/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7882\n",
      "Epoch 1519/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7904\n",
      "Epoch 1520/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.8876\n",
      "Epoch 1521/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.8461\n",
      "Epoch 1522/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8724\n",
      "Epoch 1523/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.7471\n",
      "Epoch 1524/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.8014\n",
      "Epoch 1525/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.8265\n",
      "Epoch 1526/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.8425\n",
      "Epoch 1527/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.8793\n",
      "Epoch 1528/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.8936\n",
      "Epoch 1529/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5748 - accuracy: 0.7705\n",
      "Epoch 1530/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.8943\n",
      "Epoch 1531/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7729\n",
      "Epoch 1532/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7783\n",
      "Epoch 1533/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.8977\n",
      "Epoch 1534/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.8406\n",
      "Epoch 1535/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.8250\n",
      "Epoch 1536/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.9061\n",
      "Epoch 1537/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7884\n",
      "Epoch 1538/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7114\n",
      "Epoch 1539/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.8617\n",
      "Epoch 1540/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.6976\n",
      "Epoch 1541/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.8780\n",
      "Epoch 1542/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6792\n",
      "Epoch 1543/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7708\n",
      "Epoch 1544/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.9057\n",
      "Epoch 1545/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.8386\n",
      "Epoch 1546/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8342\n",
      "Epoch 1547/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.8496\n",
      "Epoch 1548/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.8671\n",
      "Epoch 1549/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7935\n",
      "Epoch 1550/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7461\n",
      "Epoch 1551/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8882\n",
      "Epoch 1552/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.8626\n",
      "Epoch 1553/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.8158\n",
      "Epoch 1554/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7914\n",
      "Epoch 1555/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.8983\n",
      "Epoch 1556/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.8081\n",
      "Epoch 1557/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.9184\n",
      "Epoch 1558/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.8754\n",
      "Epoch 1559/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7815\n",
      "Epoch 1560/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.9252\n",
      "Epoch 1561/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.8031\n",
      "Epoch 1562/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.8245\n",
      "Epoch 1563/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.9174\n",
      "Epoch 1564/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7624\n",
      "Epoch 1565/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.8680\n",
      "Epoch 1566/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.8939\n",
      "Epoch 1567/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.6961\n",
      "Epoch 1568/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.8242\n",
      "Epoch 1569/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.8374\n",
      "Epoch 1570/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7965\n",
      "Epoch 1571/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.8227\n",
      "Epoch 1572/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7466\n",
      "Epoch 1573/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.8632\n",
      "Epoch 1574/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.9300\n",
      "Epoch 1575/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.8205\n",
      "Epoch 1576/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.8029\n",
      "Epoch 1577/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.8054\n",
      "Epoch 1578/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.8102\n",
      "Epoch 1579/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7846\n",
      "Epoch 1580/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.8387\n",
      "Epoch 1581/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7775\n",
      "Epoch 1582/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.8132\n",
      "Epoch 1583/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.7553\n",
      "Epoch 1584/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7442\n",
      "Epoch 1585/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.9041\n",
      "Epoch 1586/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7660\n",
      "Epoch 1587/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.8797\n",
      "Epoch 1588/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.8144\n",
      "Epoch 1589/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7963\n",
      "Epoch 1590/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.8834\n",
      "Epoch 1591/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5823 - accuracy: 0.8003\n",
      "Epoch 1592/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.8891\n",
      "Epoch 1593/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7295\n",
      "Epoch 1594/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7432\n",
      "Epoch 1595/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8546\n",
      "Epoch 1596/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.8879\n",
      "Epoch 1597/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7579\n",
      "Epoch 1598/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.8742\n",
      "Epoch 1599/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.8232\n",
      "Epoch 1600/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.8388\n",
      "Epoch 1601/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7839\n",
      "Epoch 1602/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7339\n",
      "Epoch 1603/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8982\n",
      "Epoch 1604/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7747\n",
      "Epoch 1605/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.8042\n",
      "Epoch 1606/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.8765\n",
      "Epoch 1607/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.9246\n",
      "Epoch 1608/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.8245\n",
      "Epoch 1609/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7675\n",
      "Epoch 1610/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.8139\n",
      "Epoch 1611/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7236\n",
      "Epoch 1612/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7764\n",
      "Epoch 1613/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.8719\n",
      "Epoch 1614/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7464\n",
      "Epoch 1615/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.8062\n",
      "Epoch 1616/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.9015\n",
      "Epoch 1617/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7972\n",
      "Epoch 1618/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.8185\n",
      "Epoch 1619/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7784\n",
      "Epoch 1620/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.8189\n",
      "Epoch 1621/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7733\n",
      "Epoch 1622/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.7488\n",
      "Epoch 1623/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.7860\n",
      "Epoch 1624/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7827\n",
      "Epoch 1625/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7821\n",
      "Epoch 1626/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8411\n",
      "Epoch 1627/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.7198\n",
      "Epoch 1628/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7641\n",
      "Epoch 1629/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.8238\n",
      "Epoch 1630/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.8741\n",
      "Epoch 1631/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7826\n",
      "Epoch 1632/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.8308\n",
      "Epoch 1633/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.8422\n",
      "Epoch 1634/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.8420\n",
      "Epoch 1635/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.8349\n",
      "Epoch 1636/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.8270\n",
      "Epoch 1637/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7263\n",
      "Epoch 1638/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.7679\n",
      "Epoch 1639/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5723 - accuracy: 0.8162\n",
      "Epoch 1640/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.8810\n",
      "Epoch 1641/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.8065\n",
      "Epoch 1642/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6728\n",
      "Epoch 1643/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.7043\n",
      "Epoch 1644/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8824\n",
      "Epoch 1645/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.6404\n",
      "Epoch 1646/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.8561\n",
      "Epoch 1647/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5532 - accuracy: 0.8809\n",
      "Epoch 1648/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.7390\n",
      "Epoch 1649/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.8221\n",
      "Epoch 1650/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.8273\n",
      "Epoch 1651/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.8231\n",
      "Epoch 1652/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.8950\n",
      "Epoch 1653/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.8439\n",
      "Epoch 1654/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.8660\n",
      "Epoch 1655/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7940\n",
      "Epoch 1656/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.8010\n",
      "Epoch 1657/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.8753\n",
      "Epoch 1658/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7617\n",
      "Epoch 1659/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.8365\n",
      "Epoch 1660/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.8072\n",
      "Epoch 1661/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.8390\n",
      "Epoch 1662/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7133\n",
      "Epoch 1663/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8828\n",
      "Epoch 1664/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7888\n",
      "Epoch 1665/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7614\n",
      "Epoch 1666/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5548 - accuracy: 0.8261\n",
      "Epoch 1667/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7876\n",
      "Epoch 1668/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.9189\n",
      "Epoch 1669/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7995\n",
      "Epoch 1670/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.7606\n",
      "Epoch 1671/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5000 - accuracy: 0.8580\n",
      "Epoch 1672/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.8500\n",
      "Epoch 1673/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.7850\n",
      "Epoch 1674/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7777\n",
      "Epoch 1675/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.7351\n",
      "Epoch 1676/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.8850\n",
      "Epoch 1677/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7809\n",
      "Epoch 1678/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.8824\n",
      "Epoch 1679/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.8982\n",
      "Epoch 1680/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.8497\n",
      "Epoch 1681/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7640\n",
      "Epoch 1682/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.8492\n",
      "Epoch 1683/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.9217\n",
      "Epoch 1684/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.8670\n",
      "Epoch 1685/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6652\n",
      "Epoch 1686/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.8819\n",
      "Epoch 1687/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8366\n",
      "Epoch 1688/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7366\n",
      "Epoch 1689/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7762\n",
      "Epoch 1690/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5486 - accuracy: 0.8767\n",
      "Epoch 1691/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.9250\n",
      "Epoch 1692/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.9015\n",
      "Epoch 1693/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.8205\n",
      "Epoch 1694/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.8549\n",
      "Epoch 1695/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.8644\n",
      "Epoch 1696/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.8783\n",
      "Epoch 1697/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.8233\n",
      "Epoch 1698/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.7644\n",
      "Epoch 1699/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.8815\n",
      "Epoch 1700/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.8769\n",
      "Epoch 1701/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5855 - accuracy: 0.7079\n",
      "Epoch 1702/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.9162\n",
      "Epoch 1703/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7909\n",
      "Epoch 1704/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.8667\n",
      "Epoch 1705/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8694\n",
      "Epoch 1706/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5858 - accuracy: 0.7793\n",
      "Epoch 1707/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.9334\n",
      "Epoch 1708/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5860 - accuracy: 0.7793\n",
      "Epoch 1709/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.8242\n",
      "Epoch 1710/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.8368\n",
      "Epoch 1711/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7517\n",
      "Epoch 1712/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7186\n",
      "Epoch 1713/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7024\n",
      "Epoch 1714/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.8257\n",
      "Epoch 1715/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.8337\n",
      "Epoch 1716/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7191\n",
      "Epoch 1717/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.8670\n",
      "Epoch 1718/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5610 - accuracy: 0.7661\n",
      "Epoch 1719/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.8952\n",
      "Epoch 1720/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.8090\n",
      "Epoch 1721/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.7813\n",
      "Epoch 1722/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8931\n",
      "Epoch 1723/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.8745\n",
      "Epoch 1724/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7947\n",
      "Epoch 1725/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7453\n",
      "Epoch 1726/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.8281\n",
      "Epoch 1727/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.8215\n",
      "Epoch 1728/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7855\n",
      "Epoch 1729/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.8483\n",
      "Epoch 1730/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.8623\n",
      "Epoch 1731/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.7874\n",
      "Epoch 1732/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7001\n",
      "Epoch 1733/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7881\n",
      "Epoch 1734/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.7359\n",
      "Epoch 1735/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.8058\n",
      "Epoch 1736/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.6362\n",
      "Epoch 1737/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6831\n",
      "Epoch 1738/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.8097\n",
      "Epoch 1739/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.8378\n",
      "Epoch 1740/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7325\n",
      "Epoch 1741/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8503\n",
      "Epoch 1742/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.8931\n",
      "Epoch 1743/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7266\n",
      "Epoch 1744/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7134\n",
      "Epoch 1745/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.8862\n",
      "Epoch 1746/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7602\n",
      "Epoch 1747/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.8179\n",
      "Epoch 1748/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7715\n",
      "Epoch 1749/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.8366\n",
      "Epoch 1750/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.8066\n",
      "Epoch 1751/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.8457\n",
      "Epoch 1752/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7755\n",
      "Epoch 1753/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.9184\n",
      "Epoch 1754/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7352\n",
      "Epoch 1755/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5700 - accuracy: 0.8499\n",
      "Epoch 1756/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8963\n",
      "Epoch 1757/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.7992\n",
      "Epoch 1758/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.8648\n",
      "Epoch 1759/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.8697\n",
      "Epoch 1760/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7442\n",
      "Epoch 1761/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5526 - accuracy: 0.8700\n",
      "Epoch 1762/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.8037\n",
      "Epoch 1763/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7971\n",
      "Epoch 1764/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7968\n",
      "Epoch 1765/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7869\n",
      "Epoch 1766/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.8190\n",
      "Epoch 1767/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6822\n",
      "Epoch 1768/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.8844\n",
      "Epoch 1769/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7156\n",
      "Epoch 1770/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.8611\n",
      "Epoch 1771/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.8652\n",
      "Epoch 1772/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.8615\n",
      "Epoch 1773/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.8809\n",
      "Epoch 1774/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.8216\n",
      "Epoch 1775/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7318\n",
      "Epoch 1776/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.8801\n",
      "Epoch 1777/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7397\n",
      "Epoch 1778/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7932\n",
      "Epoch 1779/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.7933\n",
      "Epoch 1780/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.8520\n",
      "Epoch 1781/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.8194\n",
      "Epoch 1782/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.8007\n",
      "Epoch 1783/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7966\n",
      "Epoch 1784/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.8425\n",
      "Epoch 1785/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.8758\n",
      "Epoch 1786/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.8524\n",
      "Epoch 1787/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.8458\n",
      "Epoch 1788/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7409\n",
      "Epoch 1789/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8133\n",
      "Epoch 1790/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5336 - accuracy: 0.8144\n",
      "Epoch 1791/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.8464\n",
      "Epoch 1792/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.6195\n",
      "Epoch 1793/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7563\n",
      "Epoch 1794/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.8150\n",
      "Epoch 1795/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5875 - accuracy: 0.7551\n",
      "Epoch 1796/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5378 - accuracy: 0.8071\n",
      "Epoch 1797/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.8318\n",
      "Epoch 1798/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7475\n",
      "Epoch 1799/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7786\n",
      "Epoch 1800/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7827\n",
      "Epoch 1801/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8379\n",
      "Epoch 1802/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5406 - accuracy: 0.8259\n",
      "Epoch 1803/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.8944\n",
      "Epoch 1804/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.6684\n",
      "Epoch 1805/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.8513\n",
      "Epoch 1806/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.8575\n",
      "Epoch 1807/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5364 - accuracy: 0.8492\n",
      "Epoch 1808/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.9010\n",
      "Epoch 1809/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7691\n",
      "Epoch 1810/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.7696\n",
      "Epoch 1811/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.8044\n",
      "Epoch 1812/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.8757\n",
      "Epoch 1813/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.9298\n",
      "Epoch 1814/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.9628\n",
      "Epoch 1815/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8480\n",
      "Epoch 1816/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.8345\n",
      "Epoch 1817/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8455\n",
      "Epoch 1818/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6700\n",
      "Epoch 1819/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.8008\n",
      "Epoch 1820/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.8554\n",
      "Epoch 1821/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.7891\n",
      "Epoch 1822/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7142\n",
      "Epoch 1823/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.8395\n",
      "Epoch 1824/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.8072\n",
      "Epoch 1825/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.8999\n",
      "Epoch 1826/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7238\n",
      "Epoch 1827/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.8792\n",
      "Epoch 1828/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7700\n",
      "Epoch 1829/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.8674\n",
      "Epoch 1830/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.9020\n",
      "Epoch 1831/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7894\n",
      "Epoch 1832/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.8253\n",
      "Epoch 1833/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8522\n",
      "Epoch 1834/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.8380\n",
      "Epoch 1835/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.8499\n",
      "Epoch 1836/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7206\n",
      "Epoch 1837/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.7140\n",
      "Epoch 1838/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.7802\n",
      "Epoch 1839/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.9107\n",
      "Epoch 1840/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.8814\n",
      "Epoch 1841/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7408\n",
      "Epoch 1842/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.8324\n",
      "Epoch 1843/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.8487\n",
      "Epoch 1844/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.7789\n",
      "Epoch 1845/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.8561\n",
      "Epoch 1846/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7384\n",
      "Epoch 1847/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7695\n",
      "Epoch 1848/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.8562\n",
      "Epoch 1849/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7539\n",
      "Epoch 1850/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.8163\n",
      "Epoch 1851/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.8101\n",
      "Epoch 1852/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.9147\n",
      "Epoch 1853/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7534\n",
      "Epoch 1854/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.6858\n",
      "Epoch 1855/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.7588\n",
      "Epoch 1856/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.8110\n",
      "Epoch 1857/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.8379\n",
      "Epoch 1858/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7344\n",
      "Epoch 1859/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.8610\n",
      "Epoch 1860/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.8237\n",
      "Epoch 1861/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5803 - accuracy: 0.7919\n",
      "Epoch 1862/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.8363\n",
      "Epoch 1863/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.8175\n",
      "Epoch 1864/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7613\n",
      "Epoch 1865/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7459\n",
      "Epoch 1866/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7513\n",
      "Epoch 1867/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.8371\n",
      "Epoch 1868/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.8766\n",
      "Epoch 1869/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7687\n",
      "Epoch 1870/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7757\n",
      "Epoch 1871/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7606\n",
      "Epoch 1872/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5811 - accuracy: 0.7077\n",
      "Epoch 1873/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.7071\n",
      "Epoch 1874/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5556 - accuracy: 0.8170\n",
      "Epoch 1875/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.9249\n",
      "Epoch 1876/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7695\n",
      "Epoch 1877/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.8448\n",
      "Epoch 1878/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8525\n",
      "Epoch 1879/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.7788\n",
      "Epoch 1880/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5619 - accuracy: 0.7318\n",
      "Epoch 1881/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.7651\n",
      "Epoch 1882/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.8933\n",
      "Epoch 1883/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.8844\n",
      "Epoch 1884/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.8520\n",
      "Epoch 1885/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.6793\n",
      "Epoch 1886/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8815\n",
      "Epoch 1887/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6931\n",
      "Epoch 1888/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7430\n",
      "Epoch 1889/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.8457\n",
      "Epoch 1890/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7921\n",
      "Epoch 1891/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5352 - accuracy: 0.7844\n",
      "Epoch 1892/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.8351\n",
      "Epoch 1893/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.8609\n",
      "Epoch 1894/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6037 - accuracy: 0.7070\n",
      "Epoch 1895/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.8693\n",
      "Epoch 1896/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5423 - accuracy: 0.8268\n",
      "Epoch 1897/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7747\n",
      "Epoch 1898/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.8326\n",
      "Epoch 1899/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.8492\n",
      "Epoch 1900/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.8091\n",
      "Epoch 1901/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.8415\n",
      "Epoch 1902/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8955\n",
      "Epoch 1903/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.8968\n",
      "Epoch 1904/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.9420\n",
      "Epoch 1905/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.8833\n",
      "Epoch 1906/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7662\n",
      "Epoch 1907/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.7478\n",
      "Epoch 1908/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7658\n",
      "Epoch 1909/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7232\n",
      "Epoch 1910/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5653 - accuracy: 0.8526\n",
      "Epoch 1911/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7564\n",
      "Epoch 1912/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7284\n",
      "Epoch 1913/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.9196\n",
      "Epoch 1914/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.8860\n",
      "Epoch 1915/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5686 - accuracy: 0.8580\n",
      "Epoch 1916/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7927\n",
      "Epoch 1917/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.8900\n",
      "Epoch 1918/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.7399\n",
      "Epoch 1919/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.8723\n",
      "Epoch 1920/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5690 - accuracy: 0.7910\n",
      "Epoch 1921/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.8238\n",
      "Epoch 1922/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.8440\n",
      "Epoch 1923/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.7124\n",
      "Epoch 1924/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.8764\n",
      "Epoch 1925/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.8345\n",
      "Epoch 1926/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.8287\n",
      "Epoch 1927/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.7069\n",
      "Epoch 1928/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7323\n",
      "Epoch 1929/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.6826\n",
      "Epoch 1930/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.8091\n",
      "Epoch 1931/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5815 - accuracy: 0.8168\n",
      "Epoch 1932/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7759\n",
      "Epoch 1933/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5264 - accuracy: 0.8285\n",
      "Epoch 1934/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.7826\n",
      "Epoch 1935/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.7865\n",
      "Epoch 1936/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5536 - accuracy: 0.8181\n",
      "Epoch 1937/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.8200\n",
      "Epoch 1938/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.7911\n",
      "Epoch 1939/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5602 - accuracy: 0.8362\n",
      "Epoch 1940/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7893\n",
      "Epoch 1941/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5477 - accuracy: 0.8631\n",
      "Epoch 1942/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.8536\n",
      "Epoch 1943/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.8806\n",
      "Epoch 1944/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.8332\n",
      "Epoch 1945/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.8133\n",
      "Epoch 1946/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.8971\n",
      "Epoch 1947/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.8199\n",
      "Epoch 1948/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7823\n",
      "Epoch 1949/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7908\n",
      "Epoch 1950/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.8284\n",
      "Epoch 1951/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.8364\n",
      "Epoch 1952/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7687\n",
      "Epoch 1953/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7862\n",
      "Epoch 1954/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.8606\n",
      "Epoch 1955/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.8499\n",
      "Epoch 1956/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.8750\n",
      "Epoch 1957/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.8397\n",
      "Epoch 1958/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.8068\n",
      "Epoch 1959/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.8061\n",
      "Epoch 1960/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.8444\n",
      "Epoch 1961/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.8054\n",
      "Epoch 1962/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7910\n",
      "Epoch 1963/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.8040\n",
      "Epoch 1964/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8425\n",
      "Epoch 1965/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.8728\n",
      "Epoch 1966/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5695 - accuracy: 0.8274\n",
      "Epoch 1967/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.8869\n",
      "Epoch 1968/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.8756\n",
      "Epoch 1969/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7195\n",
      "Epoch 1970/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5237 - accuracy: 0.8357\n",
      "Epoch 1971/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.8132\n",
      "Epoch 1972/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.8261\n",
      "Epoch 1973/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.8533\n",
      "Epoch 1974/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.8701\n",
      "Epoch 1975/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5748 - accuracy: 0.7752\n",
      "Epoch 1976/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.9401\n",
      "Epoch 1977/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.8727\n",
      "Epoch 1978/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.8814\n",
      "Epoch 1979/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.8249\n",
      "Epoch 1980/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5887 - accuracy: 0.6711\n",
      "Epoch 1981/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.8867\n",
      "Epoch 1982/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7633\n",
      "Epoch 1983/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.8633\n",
      "Epoch 1984/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.8352\n",
      "Epoch 1985/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.7883\n",
      "Epoch 1986/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.8057\n",
      "Epoch 1987/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.8902\n",
      "Epoch 1988/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.8347\n",
      "Epoch 1989/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.7898\n",
      "Epoch 1990/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7941\n",
      "Epoch 1991/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8333\n",
      "Epoch 1992/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.8425\n",
      "Epoch 1993/2000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7154\n",
      "Epoch 1994/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7457\n",
      "Epoch 1995/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6128\n",
      "Epoch 1996/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.8547\n",
      "Epoch 1997/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.8028\n",
      "Epoch 1998/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.8441\n",
      "Epoch 1999/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7434\n",
      "Epoch 2000/2000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7131\n"
     ]
    }
   ],
   "source": [
    "############ train ############\n",
    "hist = mlp_model.fit(x_train,\n",
    "                     y_train,\n",
    "                     batch_size=mini_batch_size,\n",
    "                     epochs=nb_epochs*10,\n",
    "                     #validation_data=(x_test,y_test),\n",
    "                     callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "scenic-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp_model.predict(x_test)\n",
    "y_pred_mlp = np.argmax(y_pred , axis=1)\n",
    "\n",
    "#mlp_model.save(file_path)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "operating-ireland",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 7 layers into a model with 4 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-509-f43328b58b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m############ load ############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#mlp_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2233\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    686\u001b[0m                      \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                      \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                      ' layers.')\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m   \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 7 layers into a model with 4 layers."
     ]
    }
   ],
   "source": [
    "############ load ############\n",
    "#mlp_model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "mlp_model.load_weights(file_path)\n",
    "\n",
    "y_pred_mlp = mlp_model.predict(x_test)\n",
    "y_pred_mlp = np.argmax(y_pred_mlp , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "vanilla-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9232245681381958\n",
      "recall: 0.9001814882032668\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:',accuracy_score(y_pred_mlp,y_true))\n",
    "print('recall:',recall_score(1-y_pred_mlp,1-y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-supply",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-landing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
